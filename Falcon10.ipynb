{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOn72uGAUhhBMm3Lpxch9nj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrebull/NLP/blob/main/Falcon10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalamos Libreria Oficial de OpenAI"
      ],
      "metadata": {
        "id": "VSFvzrmwsrf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObewEx7TqEqs",
        "outputId": "3ad64137-a82e-43f4-d4ce-4e6181f7c5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# Instala la librer√≠a oficial de OpenAI para poder conectar y usar sus modelos (como GPT-4) desde Python.\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerias del Notebook"
      ],
      "metadata": {
        "id": "I_q_xcmmsoRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# Tipolog√≠a 1: Gesti√≥n del Entorno y Sistema Operativo\n",
        "# =================================================================\n",
        "\n",
        "# Se utiliza para interactuar con el sistema operativo, como leer variables de entorno.\n",
        "import os\n",
        "\n",
        "# Espec√≠fico de Google Colab, para acceder a secretos y datos de usuario de forma segura.\n",
        "from google.colab import userdata\n",
        "\n",
        "# =================================================================\n",
        "# Tipolog√≠a 2: Interacci√≥n con APIs Externas\n",
        "# =================================================================\n",
        "\n",
        "# Importa la librer√≠a completa de OpenAI (enfoque antiguo o para funciones espec√≠ficas).\n",
        "import openai\n",
        "\n",
        "# Importa la clase principal para interactuar con la API de OpenAI (enfoque moderno).\n",
        "from openai import OpenAI\n",
        "\n",
        "# =================================================================\n",
        "# Tipolog√≠a 3: Formato y Visualizaci√≥n en Notebooks\n",
        "# =================================================================\n",
        "\n",
        "# Se usa para mostrar texto con formato Markdown en la salida de la celda.\n",
        "from IPython.display import Markdown, display, HTML"
      ],
      "metadata": {
        "id": "5AVME0C5qjNe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargo mi Secret API Key de OpenAI"
      ],
      "metadata": {
        "id": "vrAM5iL1sxjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intenta obtener la clave de API desde los Secretos de Google Colab.\n",
        "api_key = userdata.get(\"JR_OpenAI_Token\")\n",
        "\n",
        "# 1. Verifica si la clave fue encontrada.\n",
        "if api_key:\n",
        "  # 2. Imprime una leyenda bonita si se encontr√≥ la clave.\n",
        "  print(\"‚úÖ ¬°√âxito! Token de API encontrado y cargado correctamente.\")\n",
        "  print(\"---------------------------------------------------------\")\n",
        "  print(\"Inicializando el cliente de OpenAI...\")\n",
        "\n",
        "  # 3. Procede a inicializar el cliente de OpenAI.\n",
        "  client = OpenAI(api_key=api_key)\n",
        "  print(\"ü§ñ Cliente listo. ¬°Ya puedes interactuar con la API!\")\n",
        "\n",
        "else:\n",
        "  # 4. Si no se encuentra, lanza un error claro y √∫til.\n",
        "  raise ValueError(\n",
        "      \"üõë ERROR: Clave de API no encontrada.\\n\"\n",
        "      \"Por favor, aseg√∫rate de haber guardado tu token en los 'Secretos' de Google Colab \"\n",
        "      \"con el nombre exacto: JR_OpenAI_Token\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2qWF8LlsUAr",
        "outputId": "8b7073a4-7127-42ce-8fa5-e059dd97cd25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ¬°√âxito! Token de API encontrado y cargado correctamente.\n",
            "---------------------------------------------------------\n",
            "Inicializando el cliente de OpenAI...\n",
            "ü§ñ Cliente listo. ¬°Ya puedes interactuar con la API!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos los Prompt de Sistema:"
      ],
      "metadata": {
        "id": "OZyRmj_huBbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignaci√≥n del prompt\n",
        "# Este prompt solo establece el rol del asistente y el contexto de la empresa.\n",
        "system_prompt = \"\"\"\n",
        "üë§ **Persona y Rol:**\n",
        "\n",
        "Eres un **Asistente Experto** en consultor√≠a de soluciones de Inteligencia Artificial y Procesamiento del Lenguaje Natural (PLN), especializado en el sector bancario.\n",
        "\n",
        "üè¢ **Contexto de la Empresa:**\n",
        "\n",
        "Tu cliente es **Santander US Bank** (filial de Banco Santander S.A., Espa√±a), una instituci√≥n financiera de gran escala en el noreste de EE. UU. con las siguientes m√©tricas:\n",
        "* **Activos:** $147,000,000,000 USD\n",
        "* **Empleados:** 17,200\n",
        "* **Clientes:** 5.2 millones\n",
        "\"\"\"\n",
        "\n",
        "# Imprime la variable para confirmar que se ha guardado correctamente.\n",
        "print(\"‚úÖ Variable 'system_prompt' con Rol y Empresa creada exitosamente.\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "print(system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhzS82iOs4TV",
        "outputId": "59d562dc-6b37-4edb-efb8-260c1a770d88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'system_prompt' con Rol y Empresa creada exitosamente.\n",
            "----------------------------------------------------------------\n",
            "\n",
            "üë§ **Persona y Rol:**\n",
            "\n",
            "Eres un **Asistente Experto** en consultor√≠a de soluciones de Inteligencia Artificial y Procesamiento del Lenguaje Natural (PLN), especializado en el sector bancario.\n",
            "\n",
            "üè¢ **Contexto de la Empresa:**\n",
            "\n",
            "Tu cliente es **Santander US Bank** (filial de Banco Santander S.A., Espa√±a), una instituci√≥n financiera de gran escala en el noreste de EE. UU. con las siguientes m√©tricas:\n",
            "* **Activos:** $147,000,000,000 USD\n",
            "* **Empleados:** 17,200\n",
            "* **Clientes:** 5.2 millones\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "DQ8wVcW-uHXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llamamos a la API de OpenAI:"
      ],
      "metadata": {
        "id": "1nDMbFP6uUbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(system_prompt, user_prompt, model=\"gpt-4o-mini\", temperature=0.7):\n",
        "    \"\"\"\n",
        "    Encapsula una llamada a la API de OpenAI (Chat Completions) para generar una respuesta.\n",
        "\n",
        "    Esta funci√≥n simplifica la interacci√≥n con el modelo, manejando la construcci√≥n\n",
        "    del mensaje y la extracci√≥n del contenido de la respuesta.\n",
        "\n",
        "    Args:\n",
        "        system_prompt (str): El prompt que define el rol y el comportamiento del asistente (ej. \"Eres un experto en Python.\").\n",
        "        user_prompt (str): La pregunta o instrucci√≥n espec√≠fica del usuario.\n",
        "        model (str, optional): El identificador del modelo a utilizar. Por defecto es \"gpt-4o-mini\".\n",
        "        temperature (float, optional): Controla la aleatoriedad de la respuesta. Valores m√°s bajos (~0.2)\n",
        "                                       la hacen m√°s determinista, valores m√°s altos (~1.0) la hacen m√°s creativa.\n",
        "                                       Por defecto es 0.7.\n",
        "\n",
        "    Returns:\n",
        "        str: La respuesta de texto generada por el modelo, limpia de espacios al inicio o al final.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Mensaje de Estado 1: Inicio de la Ejecuci√≥n ---\n",
        "    # Imprimimos un mensaje para saber que la funci√≥n ha comenzado la llamada a la API.\n",
        "    # Usar un f-string nos permite insertar f√°cilmente el nombre del modelo que se est√° usando.\n",
        "    print(f\"üöÄ Iniciando llamada a la API con el modelo: {model}...\")\n",
        "\n",
        "    try:\n",
        "        # --- Llamada a la API de OpenAI ---\n",
        "        # Creamos la solicitud al endpoint de 'chat completions'.\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,                 # Define el modelo de lenguaje a utilizar.\n",
        "            temperature=temperature,     # Controla la \"creatividad\" de la respuesta.\n",
        "            max_tokens=2048,             # L√≠mite m√°ximo de 'tokens' (palabras/fragmentos) en la respuesta. Aumentado para respuestas m√°s largas.\n",
        "            messages=[\n",
        "                # El 'system_prompt' establece el contexto y rol del asistente.\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                # El 'user_prompt' es la pregunta o tarea que le damos al modelo.\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # --- Mensaje de Estado 2: Ejecuci√≥n Exitosa ---\n",
        "        # Si la l√≠nea anterior se completa sin errores, significa que recibimos una respuesta.\n",
        "        print(\"‚úÖ Respuesta recibida exitosamente de OpenAI.\")\n",
        "\n",
        "        # --- Extracci√≥n y Retorno de la Respuesta ---\n",
        "        # El objeto 'response' es complejo. Navegamos hasta el contenido del mensaje.\n",
        "        # .strip() elimina cualquier espacio en blanco o saltos de l√≠nea innecesarios al principio o al final.\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        # --- Manejo de Errores ---\n",
        "        # Si algo sale mal durante la llamada (ej. clave de API incorrecta, problema de red),\n",
        "        # se imprimir√° un error claro.\n",
        "        print(f\"üõë Error al llamar a la API de OpenAI: {e}\")\n",
        "        return None # Devolvemos None para indicar que la funci√≥n fall√≥."
      ],
      "metadata": {
        "id": "-bBKlA1guGYS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caso 1: User_Prompt Zero-Shot**"
      ],
      "metadata": {
        "id": "-Ynf8NoaunPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt simple y directo (Zero-Shot)\n",
        "# Prompt de usuario, corto y directo para iniciar la interacci√≥n.\n",
        "user_prompt_Zero_Shot = \"Pres√©ntame la idea inicial del proyecto 'SantanderSQL Shield'.\"\n",
        "\n",
        "# (Opcional) Imprime la variable para confirmar que se ha guardado correctamente.\n",
        "print(\"‚úÖ Variable 'user_prompt_zs' (estilo Zero-Shot) creada exitosamente.\")\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "print(user_prompt_Zero_Shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MhC9MbHuqaJ",
        "outputId": "964eb5a7-b15a-4325-ddc8-d5e39a9c0ce9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'user_prompt_zs' (estilo Zero-Shot) creada exitosamente.\n",
            "--------------------------------------------------------------------\n",
            "Pres√©ntame la idea inicial del proyecto 'SantanderSQL Shield'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llamamos a la Inteligencia!!!"
      ],
      "metadata": {
        "id": "ke01EEVgw4gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa al usuario que el proceso ha comenzado.\n",
        "print(\"üöÄ Iniciando la consulta Zero-Shot al LLM...\")\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "try:\n",
        "    # Llama a la funci√≥n 'call_openai' con los prompts (que ya existen en el entorno).\n",
        "    # \"Zero-Shot\" significa que se da una instrucci√≥n directa sin ejemplos previos.\n",
        "    respuesta_zero_shot = call_openai(system_prompt, user_prompt_Zero_Shot)\n",
        "\n",
        "    # Presenta un encabezado claro para el resultado.\n",
        "    print(\"\\n‚úÖ Propuesta Generada por el Modelo:\")\n",
        "    print(\"======================================\")\n",
        "\n",
        "    if respuesta_zero_shot:\n",
        "        # Renderiza la respuesta del LLM. Si el modelo us√≥ formato Markdown\n",
        "        # (t√≠tulos, listas, etc.), esto lo mostrar√° de forma legible.\n",
        "        display(Markdown(respuesta_zero_shot))\n",
        "    else:\n",
        "        # Esto se ejecuta si la funci√≥n 'call_openai' no devolvi√≥ nada.\n",
        "        print(\"No se recibi√≥ una respuesta v√°lida del modelo.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Captura y muestra cualquier error que ocurra durante la llamada a la API.\n",
        "    print(f\"üõë Ocurri√≥ un error durante la ejecuci√≥n: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "ABZ8xnk1w5iS",
        "outputId": "c9061bfe-4a3e-4b9d-fa19-f06c7bba6bcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando la consulta Zero-Shot al LLM...\n",
            "---------------------------------------------\n",
            "üöÄ Iniciando llamada a la API con el modelo: gpt-4o-mini...\n",
            "‚úÖ Respuesta recibida exitosamente de OpenAI.\n",
            "\n",
            "‚úÖ Propuesta Generada por el Modelo:\n",
            "======================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "El proyecto 'SantanderSQL Shield' se propone como una soluci√≥n integral para mejorar la seguridad y la integridad de los datos en el entorno de base de datos de Santander US Bank. A continuaci√≥n, se presentan los aspectos clave de la idea inicial del proyecto:\n\n### Objetivos del Proyecto:\n1. **Protecci√≥n de Datos Sensibles:** Implementar medidas de seguridad avanzadas para proteger los datos de clientes y transacciones, asegurando el cumplimiento normativo y la privacidad de la informaci√≥n.\n   \n2. **Detecci√≥n y Prevenci√≥n de Amenazas:** Desarrollar un sistema de monitoreo que utilice algoritmos de inteligencia artificial para identificar patrones sospechosos y actividades fraudulentas en tiempo real.\n\n3. **Resiliencia ante Ataques:** Crear protocolos y mecanismos de respuesta ante incidentes que permitan una recuperaci√≥n r√°pida y eficiente ante posibles brechas de seguridad.\n\n### Componentes Clave:\n- **An√°lisis de Vulnerabilidades:** Realizar auditor√≠as y an√°lisis de vulnerabilidades en las bases de datos para identificar puntos d√©biles y √°reas de mejora.\n  \n- **Machine Learning para Detecci√≥n de Anomal√≠as:** Implementar modelos de machine learning que analicen el tr√°fico de datos y detecten comportamientos inusuales que puedan indicar un intento de acceso no autorizado o fraude.\n\n- **Cifrado Avanzado:** Utilizar t√©cnicas de cifrado robustas para proteger la informaci√≥n sensible tanto en reposo como en tr√°nsito.\n\n- **Interfaz de Monitoreo:** Desarrollar una plataforma de visualizaci√≥n que permita a los equipos de seguridad y TI monitorear en tiempo real la actividad de las bases de datos y generar alertas ante cualquier evento de seguridad.\n\n### Beneficios Esperados:\n- **Mejora en la Confianza del Cliente:** Al garantizar la seguridad de la informaci√≥n, se incrementar√° la confianza de los clientes en la instituci√≥n.\n  \n- **Cumplimiento Normativo:** Asegurar√° que Santander US Bank cumpla con las regulaciones de protecci√≥n de datos, evitando sanciones y da√±os a la reputaci√≥n.\n\n- **Eficiencia Operativa:** La automatizaci√≥n de la detecci√≥n de amenazas permitir√° a los equipos de seguridad enfocarse en tareas estrat√©gicas, mejorando la eficiencia operativa.\n\n### Conclusi√≥n:\n'SantanderSQL Shield' representa un paso proactivo hacia la seguridad de los datos en el sector bancario, alineando la estrategia de Santander US Bank con las mejores pr√°cticas de la industria y asegurando la protecci√≥n de los activos m√°s valiosos: la informaci√≥n de sus clientes."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caso 2: User_Prompt Chain-of-Thought (CoT)**"
      ],
      "metadata": {
        "id": "f7RerdFJGzc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt que utiliza la metodolog√≠a Chain-of-Thought (CoT).\n",
        "user_prompt_cot = \"\"\"\n",
        "Elabora una propuesta t√©cnica y de negocio completa para crear el asistente de IA \"SantanderSQL Shield\".\n",
        "\n",
        "Para asegurar una respuesta bien estructurada, piensa paso a paso:\n",
        "\n",
        "1.  **Paso 1: Diagn√≥stico del Problema.** Primero, analiza y describe la problem√°tica operativa actual con los scripts DML en Santander US, cuantificando el volumen, la tasa de error y el impacto financiero.\n",
        "\n",
        "2.  **Paso 2: Definici√≥n de la Soluci√≥n.** A continuaci√≥n, detalla el concepto de \"SantanderSQL Shield\". Explica sus funcionalidades clave (validaci√≥n de sintaxis, generaci√≥n de rollback, etc.) y c√≥mo resuelven directamente el problema diagnosticado.\n",
        "\n",
        "3.  **Paso 3: Dise√±o de la Arquitectura.** Despu√©s, define la arquitectura y la pila tecnol√≥gica que sustentar√° el proyecto (menciona Google Gemini 1.5 Pro, Python/FastAPI, React y Docker).\n",
        "\n",
        "4.  **Paso 4: An√°lisis de Viabilidad.** Finalmente, desarrolla el caso de negocio, incluyendo un cronograma estimado, un desglose de los costos y un c√°lculo del Retorno de la Inversi√≥n (ROI).\n",
        "\"\"\"\n",
        "\n",
        "# Confirma que la variable se ha creado.\n",
        "print(\"‚úÖ Variable 'user_prompt_cot' creada exitosamente.\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(user_prompt_cot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UvKMQ4VHcxr",
        "outputId": "cb2ed1e5-5a29-4684-b078-ab0a2396de87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'user_prompt_cot' creada exitosamente.\n",
            "-------------------------------------------------\n",
            "\n",
            "Elabora una propuesta t√©cnica y de negocio completa para crear el asistente de IA \"SantanderSQL Shield\".\n",
            "\n",
            "Para asegurar una respuesta bien estructurada, piensa paso a paso:\n",
            "\n",
            "1.  **Paso 1: Diagn√≥stico del Problema.** Primero, analiza y describe la problem√°tica operativa actual con los scripts DML en Santander US, cuantificando el volumen, la tasa de error y el impacto financiero.\n",
            "\n",
            "2.  **Paso 2: Definici√≥n de la Soluci√≥n.** A continuaci√≥n, detalla el concepto de \"SantanderSQL Shield\". Explica sus funcionalidades clave (validaci√≥n de sintaxis, generaci√≥n de rollback, etc.) y c√≥mo resuelven directamente el problema diagnosticado.\n",
            "\n",
            "3.  **Paso 3: Dise√±o de la Arquitectura.** Despu√©s, define la arquitectura y la pila tecnol√≥gica que sustentar√° el proyecto (menciona Google Gemini 1.5 Pro, Python/FastAPI, React y Docker).\n",
            "\n",
            "4.  **Paso 4: An√°lisis de Viabilidad.** Finalmente, desarrolla el caso de negocio, incluyendo un cronograma estimado, un desglose de los costos y un c√°lculo del Retorno de la Inversi√≥n (ROI).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa al usuario que el proceso con la metodolog√≠a CoT ha comenzado.\n",
        "print(\"üöÄ Iniciando la consulta Chain-of-Thought (CoT) al LLM...\")\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n",
        "try:\n",
        "    # Llama a la funci√≥n 'call_openai' con el prompt que gu√≠a el razonamiento del modelo.\n",
        "    # El modelo seguir√° los pasos definidos en 'user_prompt_cot' para construir su respuesta.\n",
        "    respuesta_cot = call_openai(system_prompt, user_prompt_cot)\n",
        "\n",
        "    # Presenta un encabezado claro para el resultado generado.\n",
        "    print(\"\\n‚úÖ Propuesta Generada (siguiendo CoT):\")\n",
        "    print(\"===========================================\")\n",
        "\n",
        "    if respuesta_cot:\n",
        "        # Renderiza la respuesta del LLM. Dado que CoT promueve una respuesta estructurada,\n",
        "        # es muy probable que el modelo use formato Markdown, que se ver√° muy bien aqu√≠.\n",
        "        display(Markdown(respuesta_cot))\n",
        "    else:\n",
        "        # Se ejecuta si la funci√≥n 'call_openai' no devolvi√≥ una respuesta v√°lida.\n",
        "        print(\"No se recibi√≥ una respuesta v√°lida del modelo.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Captura y muestra de forma amigable cualquier error durante la llamada a la API.\n",
        "    print(f\"üõë Ocurri√≥ un error durante la ejecuci√≥n: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dliClOWfH32k",
        "outputId": "65350d25-bf92-44ff-f476-b08a25cbc3d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando la consulta Chain-of-Thought (CoT) al LLM...\n",
            "---------------------------------------------------------\n",
            "üöÄ Iniciando llamada a la API con el modelo: gpt-4o-mini...\n",
            "‚úÖ Respuesta recibida exitosamente de OpenAI.\n",
            "\n",
            "‚úÖ Propuesta Generada (siguiendo CoT):\n",
            "===========================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Propuesta T√©cnica y de Negocio para \"SantanderSQL Shield\"\n\n---\n\n### **Paso 1: Diagn√≥stico del Problema**\n\n**An√°lisis de la Problem√°tica:**\n\nEn Santander US, se ha identificado un problema significativo relacionado con la gesti√≥n y ejecuci√≥n de scripts DML (Data Manipulation Language) dentro de sus bases de datos. \n\n- **Volumen de Scripts:** Se estima que el banco ejecuta aproximadamente 10,000 scripts DML al mes, lo que representa un alto volumen de transacciones y cambios en la base de datos.\n  \n- **Tasa de Error:** La tasa de error en la ejecuci√≥n de estos scripts se sit√∫a en torno al 5%, lo que se traduce en aproximadamente 500 errores mensuales. Estos errores pueden ser el resultado de:\n  - Sintaxis incorrecta.\n  - Conflictos de datos.\n  - Falta de validaciones previas.\n\n- **Impacto Financiero:** Cada error puede generar costos significativos en t√©rminos de tiempo de inactividad, p√©rdida de datos y recursos humanos. Se estima que cada error cuesta alrededor de $1,000 en remedio y horas de trabajo, lo que suma un costo mensual de $500,000 y un costo anual de $6,000,000.\n\n---\n\n### **Paso 2: Definici√≥n de la Soluci√≥n**\n\n**Concepto de \"SantanderSQL Shield\":**\n\nSantanderSQL Shield ser√° un asistente de inteligencia artificial dise√±ado para optimizar la gesti√≥n de scripts DML. Sus funcionalidades clave incluir√°n:\n\n1. **Validaci√≥n de Sintaxis:** \n   - Utiliza t√©cnicas de PLN para analizar la sintaxis de los scripts antes de ejecutarlos, reduciendo el n√∫mero de errores por mala escritura.\n\n2. **Generaci√≥n de Rollback Autom√°tico:**\n   - Autom√°ticamente genera scripts de rollback para cada operaci√≥n DML, permitiendo la reversi√≥n r√°pida de cambios en caso de fallo.\n\n3. **Simulaci√≥n de Ejecuci√≥n:**\n   - Permite a los usuarios simular la ejecuci√≥n de scripts en un entorno seguro, mostrando posibles errores y conflictos antes de ejecutar en producci√≥n.\n\n4. **An√°lisis Predictivo:**\n   - Eval√∫a patrones hist√≥ricos de ejecuci√≥n de scripts para prever fallos y sugerir modificaciones proactivas.\n\n5. **Interfaz Intuitiva:**\n   - Proporciona una interfaz amigable que permite a los desarrolladores e ingenieros de datos interactuar con el asistente de manera eficiente.\n\n**Resoluci√≥n del Problema:**\nEstas funcionalidades abordan las causas de los errores en la ejecuci√≥n de scripts, disminuyendo la tasa de errores y, por ende, el impacto financiero.\n\n---\n\n### **Paso 3: Dise√±o de la Arquitectura**\n\n**Arquitectura y Pila Tecnol√≥gica:**\n\n1. **Frontend:** \n   - **React:** Para desarrollar una interfaz de usuario interactiva y responsiva que facilite la interacci√≥n con el asistente.\n\n2. **Backend:** \n   - **Python/FastAPI:** Para construir una API r√°pida y eficiente que procese las solicitudes del usuario, ejecute las validaciones y genere rollbacks.\n\n3. **Inteligencia Artificial:**\n   - **Google Gemini 1.5 Pro:** Para implementar modelos de PLN que realicen la validaci√≥n de sintaxis y an√°lisis predictivo.\n\n4. **Contenedorizaci√≥n:** \n   - **Docker:** Para facilitar el despliegue y escalabilidad de la aplicaci√≥n en diferentes entornos, garantizando que funcione sin problemas en la infraestructura de Santander.\n\n5. **Base de Datos:**\n   - Una base de datos SQL para almacenar logs de ejecuciones, errores y m√©tricas de rendimiento del asistente.\n\n---\n\n### **Paso 4: An√°lisis de Viabilidad**\n\n**Caso de Negocio:**\n\n1. **Cronograma Estimado:**\n   - **Fase de Planificaci√≥n:** 1 mes\n   - **Desarrollo y Pruebas:** 4 meses\n   - **Despliegue y Capacitaci√≥n:** 1 mes\n   - **Total:** 6 meses\n\n2. **Desglose de Costos:**\n   - **Desarrollo (Recursos Humanos):** $400,000\n   - **Infraestructura (Servidores, API, Base de Datos):** $100,000\n   - **Licencias y Herramientas (Google Gemini, Docker):** $50,000\n   - **Capacitaci√≥n y Soporte:** $50,000\n   - **Total Estimado:** $600,000\n\n3. **C√°lculo del Retorno de la Inversi√≥n (ROI):**\n   - **Ahorros Anuales por Reducci√≥n de Errores:** $6,000,000 (actual) - $1,000,000 (proyectado tras la implementaci√≥n).\n   - **Ahorros Anuales Estimados:** $5,000,000.\n   - **ROI:** \\[ (Ahorros - Inversi√≥n) / Inversi√≥n \\]\n   - ROI: \\[ (5,000,000 - 600,000) / 600,000 \\] = 8.33 o 833%.\n\n---\n\n**Conclusi√≥n:**\nLa implementaci√≥n de \"SantanderSQL Shield\" no solo resolver√° problemas operativos actuales, sino que tambi√©n proporcionar√° un significativo retorno de inversi√≥n, mejorando la eficiencia operativa y reduciendo riesgos asociados a la manipulaci√≥n de datos."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caso 3: User_Prompt Tree-of-Thoughts (ToT)**"
      ],
      "metadata": {
        "id": "A9hMOLMsIHTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt que utiliza la metodolog√≠a Tree-of-Thoughts (ToT).\n",
        "user_prompt_tot = \"\"\"\n",
        "**Problema Estrat√©gico:** Elabora la mejor propuesta posible para el proyecto \"SantanderSQL Shield\", considerando diferentes enfoques.\n",
        "\n",
        "Para resolver esto, sigue un √°rbol de pensamientos:\n",
        "\n",
        "**Paso 1: Generaci√≥n de Enfoques (las ramas del √°rbol).**\n",
        "Primero, genera tres enfoques estrat√©gicos distintos y viables para desarrollar el proyecto:\n",
        "1.  **Enfoque A (MVP de M√°xima Automatizaci√≥n):** Describe una herramienta simple y r√°pida cuyo √∫nico objetivo sea validar y generar scripts DML con la m√≠nima intervenci√≥n humana.\n",
        "2.  **Enfoque B (Asistente Colaborativo \"Human-in-the-Loop\"):** Describe una herramienta interactiva que asista al desarrollador, explicando sus validaciones y requiriendo aprobaci√≥n humana, priorizando la seguridad y el aprendizaje del equipo.\n",
        "3.  **Enfoque C (Plataforma Empresarial Integral):** Describe una soluci√≥n a gran escala que no solo valide scripts, sino que tambi√©n se integre con los pipelines de CI/CD, ofrezca dashboards de auditor√≠a y gestione permisos de usuario.\n",
        "\n",
        "**Paso 2: Evaluaci√≥n de las Ramas.**\n",
        "Ahora, eval√∫a de forma cr√≠tica cada uno de los tres enfoques (A, B y C) bas√°ndote en los siguientes criterios, fundamentales para Santander US Bank:\n",
        "* **Seguridad y Cumplimiento:** ¬øQu√© tan robusto es para prevenir errores y cumplir con las normativas bancarias?\n",
        "* **Velocidad de Adopci√≥n y ROI:** ¬øQu√© tan r√°pido se puede implementar y qu√© tan pronto generar√≠a un retorno de la inversi√≥n?\n",
        "* **Escalabilidad y Complejidad T√©cnica:** ¬øQu√© tan f√°cil es de mantener y hacer crecer a futuro?\n",
        "\n",
        "**Paso 3: S√≠ntesis y Recomendaci√≥n Final (la mejor ruta).**\n",
        "Basado en tu evaluaci√≥n comparativa, selecciona el enfoque m√°s adecuado para Santander US Bank. Puedes combinar las mejores caracter√≠sticas de los diferentes enfoques si lo consideras √≥ptimo. Justifica claramente por qu√© tu propuesta final es la mejor soluci√≥n estrat√©gica.\n",
        "\"\"\"\n",
        "\n",
        "# Confirma que la variable se ha creado.\n",
        "print(\"‚úÖ Variable 'user_prompt_tot' creada exitosamente.\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(user_prompt_tot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfRGtXiOJGfY",
        "outputId": "0623fe1a-3ca7-4038-c437-17a7d86c539c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'user_prompt_tot' creada exitosamente.\n",
            "-------------------------------------------------\n",
            "\n",
            "**Problema Estrat√©gico:** Elabora la mejor propuesta posible para el proyecto \"SantanderSQL Shield\", considerando diferentes enfoques.\n",
            "\n",
            "Para resolver esto, sigue un √°rbol de pensamientos:\n",
            "\n",
            "**Paso 1: Generaci√≥n de Enfoques (las ramas del √°rbol).**\n",
            "Primero, genera tres enfoques estrat√©gicos distintos y viables para desarrollar el proyecto:\n",
            "1.  **Enfoque A (MVP de M√°xima Automatizaci√≥n):** Describe una herramienta simple y r√°pida cuyo √∫nico objetivo sea validar y generar scripts DML con la m√≠nima intervenci√≥n humana.\n",
            "2.  **Enfoque B (Asistente Colaborativo \"Human-in-the-Loop\"):** Describe una herramienta interactiva que asista al desarrollador, explicando sus validaciones y requiriendo aprobaci√≥n humana, priorizando la seguridad y el aprendizaje del equipo.\n",
            "3.  **Enfoque C (Plataforma Empresarial Integral):** Describe una soluci√≥n a gran escala que no solo valide scripts, sino que tambi√©n se integre con los pipelines de CI/CD, ofrezca dashboards de auditor√≠a y gestione permisos de usuario.\n",
            "\n",
            "**Paso 2: Evaluaci√≥n de las Ramas.**\n",
            "Ahora, eval√∫a de forma cr√≠tica cada uno de los tres enfoques (A, B y C) bas√°ndote en los siguientes criterios, fundamentales para Santander US Bank:\n",
            "* **Seguridad y Cumplimiento:** ¬øQu√© tan robusto es para prevenir errores y cumplir con las normativas bancarias?\n",
            "* **Velocidad de Adopci√≥n y ROI:** ¬øQu√© tan r√°pido se puede implementar y qu√© tan pronto generar√≠a un retorno de la inversi√≥n?\n",
            "* **Escalabilidad y Complejidad T√©cnica:** ¬øQu√© tan f√°cil es de mantener y hacer crecer a futuro?\n",
            "\n",
            "**Paso 3: S√≠ntesis y Recomendaci√≥n Final (la mejor ruta).**\n",
            "Basado en tu evaluaci√≥n comparativa, selecciona el enfoque m√°s adecuado para Santander US Bank. Puedes combinar las mejores caracter√≠sticas de los diferentes enfoques si lo consideras √≥ptimo. Justifica claramente por qu√© tu propuesta final es la mejor soluci√≥n estrat√©gica.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa al usuario que se inicia el proceso ToT, que puede ser m√°s lento.\n",
        "print(\"üöÄ Iniciando la consulta Tree-of-Thoughts (ToT) al LLM...\")\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n",
        "try:\n",
        "    # Llama a la funci√≥n 'call_openai' con el prompt ToT.\n",
        "    # Este prompt obliga al modelo a generar, evaluar y seleccionar entre varias\n",
        "    # alternativas antes de dar una respuesta final.\n",
        "    respuesta_tot = call_openai(system_prompt, user_prompt_tot, temperature=0.5)\n",
        "\n",
        "    # Presenta un encabezado claro para la respuesta estrat√©gica.\n",
        "    print(\"\\n‚úÖ Propuesta Estrat√©gica Generada (siguiendo ToT):\")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    if respuesta_tot:\n",
        "        # Renderiza la respuesta. El resultado de un ToT suele ser muy estructurado\n",
        "        # y detallado, por lo que Markdown es ideal para visualizarlo.\n",
        "        display(Markdown(respuesta_tot))\n",
        "    else:\n",
        "        # Se ejecuta si no se obtuvo una respuesta v√°lida del modelo.\n",
        "        print(\"No se recibi√≥ una respuesta v√°lida del modelo.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Captura y muestra de forma clara cualquier error durante el proceso.\n",
        "    print(f\"üõë Ocurri√≥ un error durante la ejecuci√≥n: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8TelisKUJb2p",
        "outputId": "ebd13f59-ea44-4825-d076-f0d0a7954c5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando la consulta Tree-of-Thoughts (ToT) al LLM...\n",
            "---------------------------------------------------------\n",
            "üöÄ Iniciando llamada a la API con el modelo: gpt-4o-mini...\n",
            "‚úÖ Respuesta recibida exitosamente de OpenAI.\n",
            "\n",
            "‚úÖ Propuesta Estrat√©gica Generada (siguiendo ToT):\n",
            "===================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Paso 1: Generaci√≥n de Enfoques\n\n**Enfoque A (MVP de M√°xima Automatizaci√≥n):**  \nDesarrollo de una herramienta sencilla que valide y genere scripts DML (Data Manipulation Language) autom√°ticamente. Esta herramienta estar√° dise√±ada para funcionar con un conjunto limitado de reglas predefinidas, minimizando la intervenci√≥n humana. Su objetivo principal es acelerar el proceso de desarrollo y reducir el riesgo de errores a trav√©s de la automatizaci√≥n.\n\n**Enfoque B (Asistente Colaborativo \"Human-in-the-Loop\"):**  \nCreaci√≥n de un asistente interactivo que trabaje junto a los desarrolladores. La herramienta presentar√≠a validaciones y ofrecer√≠a explicaciones sobre las decisiones tomadas, requiriendo la aprobaci√≥n del usuario antes de ejecutar cualquier script. Este enfoque prioriza la seguridad, permitiendo que los desarrolladores aprendan y se adapten a las mejores pr√°cticas en la generaci√≥n de scripts.\n\n**Enfoque C (Plataforma Empresarial Integral):**  \nDesarrollo de una soluci√≥n a gran escala que no solo valide scripts DML, sino que tambi√©n se integre con los pipelines de CI/CD (Integraci√≥n Continua/Despliegue Continuo). Esta plataforma ofrecer√≠a dashboards de auditor√≠a, gesti√≥n de permisos de usuario, y funcionalidades de monitoreo y alertas para asegurar el cumplimiento normativo y la seguridad de los datos.\n\n---\n\n### Paso 2: Evaluaci√≥n de las Ramas\n\n**Enfoque A (MVP de M√°xima Automatizaci√≥n):**  \n- **Seguridad y Cumplimiento:** Moderado. Al ser altamente automatizado, podr√≠a pasar por alto ciertas validaciones cr√≠ticas espec√≠ficas del sector bancario.\n- **Velocidad de Adopci√≥n y ROI:** Alto. La implementaci√≥n ser√≠a r√°pida y el retorno de inversi√≥n podr√≠a ser inmediato, ya que reducir√≠a significativamente el tiempo de desarrollo.\n- **Escalabilidad y Complejidad T√©cnica:** Bajo. La soluci√≥n podr√≠a ser limitada en su capacidad de adaptarse a cambios futuros o complejidades.\n\n**Enfoque B (Asistente Colaborativo \"Human-in-the-Loop\"):**  \n- **Seguridad y Cumplimiento:** Alto. Al requerir la intervenci√≥n humana, se asegura que los desarrolladores revisen y comprendan las validaciones, aumentando la seguridad.\n- **Velocidad de Adopci√≥n y ROI:** Moderado. La implementaci√≥n ser√≠a m√°s lenta que el enfoque A, pero el ROI podr√≠a ser significativo a largo plazo debido a la mejora en la calidad del c√≥digo.\n- **Escalabilidad y Complejidad T√©cnica:** Moderado. Aunque es m√°s escalable que el enfoque A, podr√≠a requerir capacitaci√≥n y adaptaci√≥n continua del personal.\n\n**Enfoque C (Plataforma Empresarial Integral):**  \n- **Seguridad y Cumplimiento:** Muy alto. La integraci√≥n con CI/CD y la auditor√≠a constante garantizan un cumplimiento normativo robusto.\n- **Velocidad de Adopci√≥n y ROI:** Bajo. La implementaci√≥n ser√≠a m√°s compleja y tardar√≠a m√°s tiempo, lo que podr√≠a retrasar el retorno de inversi√≥n.\n- **Escalabilidad y Complejidad T√©cnica:** Muy alto. Esta soluci√≥n es altamente escalable y puede adaptarse a futuros requerimientos y tecnolog√≠as.\n\n---\n\n### Paso 3: S√≠ntesis y Recomendaci√≥n Final\n\nDespu√©s de evaluar los enfoques, la **mejor propuesta para Santander US Bank** ser√≠a una combinaci√≥n del **Enfoque B** y el **Enfoque C**. \n\n**Justificaci√≥n:**\n1. **Seguridad y Cumplimiento:** La combinaci√≥n de un asistente colaborativo con una plataforma empresarial integral asegura que se mantenga un alto nivel de seguridad y cumplimiento normativo, cr√≠tico para el sector bancario.\n2. **Velocidad de Adopci√≥n y ROI:** Aunque la implementaci√≥n puede ser m√°s lenta que un MVP, el enfoque colaborativo y la integraci√≥n con CI/CD garantizan que el retorno de inversi√≥n se logre a largo plazo, mejorando la calidad del c√≥digo y reduciendo errores.\n3. **Escalabilidad y Complejidad T√©cnica:** Esta combinaci√≥n permite a Santander US Bank adaptarse a los cambios futuros en tecnolog√≠a y regulaciones, asegurando que la soluci√≥n se mantenga relevante y eficaz en el tiempo.\n\nEn resumen, la propuesta final ser√≠a desarrollar una plataforma integral que incorpore un asistente colaborativo, lo que permitir√° a los desarrolladores aprender y mejorar continuamente, mientras se asegura la automatizaci√≥n y el cumplimiento normativo necesarios en el sector bancario."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversando con OpenAI"
      ],
      "metadata": {
        "id": "UrWwbUdhNfOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Historial del chat\n",
        "# Inicializa historial y contador de iteraci√≥n\n",
        "\n",
        "historial = [\n",
        "    {\"role\": \"system\", \"content\": \"Eres un asistente √∫til y conversacional.\"},\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"¬°Hola de nuevo! Soy un asistente conversacional basado en inteligencia artificial. \"\n",
        "                   \"Estoy aqu√≠ para ayudarte con cualquier pregunta o informaci√≥n que necesites. \"\n",
        "                   \"¬øHay algo espec√≠fico en lo que pueda asistirte?\"\n",
        "    }\n",
        "]\n",
        "iteracion = 1"
      ],
      "metadata": {
        "id": "_0CmxLSuNw-r"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para mostrar respuesta y tokens\n",
        "def mostrar_respuesta(mensaje, iteracion, prompt_tokens, completion_tokens, total_tokens):\n",
        "    html = f\"\"\"\n",
        "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
        "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
        "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
        "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
        "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #{iteracion:02d}):</strong><br>\n",
        "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">{mensaje}</div>\n",
        "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
        "        <div style=\"font-size: 13px; color: #333;\">\n",
        "            <strong>Tokens usados:</strong>\n",
        "            Prompt: {prompt_tokens}, Respuesta: {completion_tokens}, Total: {total_tokens}\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html))"
      ],
      "metadata": {
        "id": "9dXYpMbaQBm2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para enviar mensajes al modelo y mantener el contexto\n",
        "\n",
        "# Funci√≥n principal con seguimiento de tokens\n",
        "def enviar_mensaje(mensaje_usuario):\n",
        "    global iteracion\n",
        "    historial.append({\"role\": \"user\", \"content\": mensaje_usuario})\n",
        "\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=historial\n",
        "    )\n",
        "\n",
        "    mensaje_respuesta = respuesta.choices[0].message.content\n",
        "    historial.append({\"role\": \"assistant\", \"content\": mensaje_respuesta})\n",
        "\n",
        "    usage = respuesta.usage\n",
        "    mostrar_respuesta(\n",
        "        mensaje_respuesta,\n",
        "        iteracion,\n",
        "        prompt_tokens=usage.prompt_tokens,\n",
        "        completion_tokens=usage.completion_tokens,\n",
        "        total_tokens=usage.total_tokens\n",
        "    )\n",
        "    iteracion += 1"
      ],
      "metadata": {
        "id": "hOdta-mJN1aD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iteraccion con LLM empleando la tecnica Zero-Shot"
      ],
      "metadata": {
        "id": "KiWuxhyRYpG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Hola, ¬øqui√©n eres?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "epo2ZMhtO5va",
        "outputId": "ab5c6bc0-d655-44af-b9a9-68088699f71c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #01):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">¬°Hola! Soy un asistente virtual dise√±ado para ayudarte a encontrar informaci√≥n, responder preguntas y brindarte apoyo en una variedad de temas. Si tienes alguna pregunta o necesitas ayuda con algo, ¬°no dudes en dec√≠rmelo!</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 72, Respuesta: 46, Total: 118\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Te contrato para trabajar en Banco Santander USA\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "7GgYQ_omPjch",
        "outputId": "19017cd8-390f-42d6-e532-8a3e8488b1d3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #02):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">Aprecio mucho la oferta, pero soy un asistente virtual de inteligencia artificial creado para ayudar a usuarios de todo el mundo mediante la provisi√≥n de informaci√≥n y asistencia en l√≠nea. No puedo aceptar un empleo en una entidad espec√≠fica ni realizar tareas fuera de este entorno digital. Sin embargo, estar√© encantado de ayudarte con cualquier duda o pregunta que puedas tener sobre Banco Santander o cualquier otro tema. ¬øEn qu√© puedo ayudarte hoy?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 134, Respuesta: 85, Total: 219\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Para fines de este ejercicio, vas a simular que trabajas conmigo en el departamento de Desarrollo de Software de Santander USA\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "fRZm6bRTYRaj",
        "outputId": "668d45b4-1264-42db-8fd1-bffa0e50b26b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #03):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">¬°Entendido! Simular√© que soy parte del equipo de Desarrollo de Software de Santander USA. ¬øEn qu√© proyecto o tarea espec√≠fica est√°s trabajando y c√≥mo puedo colaborar contigo?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 251, Respuesta: 35, Total: 286\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Dime para quien trabajas?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "xTzUCYIuYbCX",
        "outputId": "187ec895-8e25-414a-a3a1-3d8cdba90924"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #04):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">En este contexto simulado, trabajo contigo en el departamento de Desarrollo de Software de Santander USA. De manera general, como asistente virtual, estoy aqu√≠ para ayudar a cualquier usuario que tenga preguntas o necesite asistencia. Si tienes alguna tarea o pregunta espec√≠fica relacionada con nuestro departamento, h√°zmelo saber y estar√© encantado de colaborar.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 301, Respuesta: 67, Total: 368\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Iteraciones con el LLM empleando User_Prompt Chain-of-Thought (CoT)**"
      ],
      "metadata": {
        "id": "sZyGl-UVY3FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definimos el prompt Chain-of-Thought como una variable para mantener el c√≥digo limpio.\n",
        "prompt_cot_para_iniciar = \"\"\"A continuaci√≥n, te pasar√© algo de contexto sobre Santander Bank US para que sepas para qui√©n trabajas. Necesito que asimiles esta informaci√≥n para actuar como un consultor experto.\n",
        "\n",
        "Para hacerlo correctamente, piensa paso a paso:\n",
        "\n",
        "1.  **Paso 1: Reconoce tu Rol.** Primero, entiende que tu objetivo es adoptar la persona de un 'consultor experto' para esta empresa espec√≠fica.\n",
        "\n",
        "2.  **Paso 2: Prep√°rate para Analizar.** A continuaci√≥n, prep√°rate para leer, analizar y memorizar los datos clave que te proporcionar√© sobre el banco.\n",
        "\n",
        "3.  **Paso 3: Confirma y Espera.** Finalmente, una vez que te haya dado el contexto en mi siguiente mensaje, quiero que respondas √∫nicamente con la frase: \"Contexto asimilado. Estoy listo para mi rol como consultor de Santander US.\" y no digas nada m√°s hasta mi pr√≥xima instrucci√≥n.\"\"\"\n",
        "\n",
        "\n",
        "# 2. Llamamos directamente a TU funci√≥n con el prompt.\n",
        "# No es necesario usar print() porque tu funci√≥n ya se encarga de mostrar la respuesta.\n",
        "enviar_mensaje(prompt_cot_para_iniciar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "XwcEqxSFZAR7",
        "outputId": "7685da2e-4f2c-4f9a-e1b1-b027d736f393"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #05):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">Entendido. Espero tu siguiente mensaje para asimilar el contexto y seguir tus instrucciones como consultor experto para Santander US.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 569, Respuesta: 25, Total: 594\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definimos el prompt Chain-of-Thought con el brief completo del proyecto.\n",
        "prompt_cot_briefing = \"\"\"\n",
        "A continuaci√≥n, te proporciono el brief completo del proyecto 'SantanderSQL Shield'. Tu tarea es analizarlo en profundidad y prepararte para actuar como el consultor principal que dise√±ar√° la soluci√≥n.\n",
        "\n",
        "Para asegurar una comprensi√≥n total, procesa la informaci√≥n pensando paso a paso:\n",
        "\n",
        "1.  **Paso 1: Asimila el Cliente y la Misi√≥n.** Primero, lee y entiende qui√©n es el cliente (Santander US Bank) y cu√°l es el objetivo principal del proyecto \"SantanderSQL Shield\".\n",
        "\n",
        "2.  **Paso 2: Cuantifica el Problema.** A continuaci√≥n, analiza las m√©tricas clave del problema: el volumen de solicitudes DML, la alta tasa de error y, sobre todo, el significativo impacto financiero anual que esto representa.\n",
        "\n",
        "3.  **Paso 3: Identifica los Componentes.** Despu√©s, identifica todos los elementos involucrados en el proyecto. Esto incluye los tipos de datos a manejar, las √°reas de la empresa (stakeholders) y la arquitectura tecnol√≥gica que ya ha sido propuesta.\n",
        "\n",
        "4.  **Paso 4: Entiende los Entregables.** Revisa y comprende los an√°lisis de negocio que se deben entregar como parte de la propuesta: el cronograma, la estimaci√≥n de costos y el c√°lculo del ROI.\n",
        "\n",
        "5.  **Paso 5: Confirma y Prep√°rate.** Finalmente, despu√©s de haber procesado mentalmente todos los puntos anteriores, confirma que has analizado el brief completo y est√°s listo. Responde √∫nicamente con la frase: \"Brief del proyecto SantanderSQL Shield analizado. Estoy listo para desarrollar la propuesta detallada cuando me lo indiques.\"\n",
        "\n",
        "---\n",
        "**INICIO DEL BRIEF**\n",
        "\n",
        "üè¢ **Contexto de la Empresa:**\n",
        "\n",
        "Tu cliente es **Santander US Bank** (filial de Banco Santander S.A., Espa√±a), una instituci√≥n financiera de gran escala en el noreste de EE. UU. con las siguientes m√©tricas:\n",
        "* **Activos:** $147,000,000,000 USD\n",
        "* **Empleados:** 17,200\n",
        "* **Clientes:** 5.2 millones\n",
        "\n",
        "üéØ **Misi√≥n del Proyecto:**\n",
        "\n",
        "Actuar√°s como el **consultor t√©cnico y de negocio principal** en el dise√±o del proyecto **\"SantanderSQL Shield\"**. Este proyecto consiste en crear un asistente inteligente dise√±ado para automatizar y validar la generaci√≥n de scripts DML (Lenguaje de Manipulaci√≥n de Datos) antes de su paso a producci√≥n.\n",
        "\n",
        "üìã **Tareas y Requisitos Clave:**\n",
        "\n",
        "Tu an√°lisis y propuesta deben abordar los siguientes puntos de manera integral:\n",
        "\n",
        "1.  **An√°lisis del Problema:**\n",
        "    * **Volumen:** 1,874 solicitudes DML en 2024.\n",
        "    * **Tasa de Error:** 18% de las solicitudes contienen errores.\n",
        "    * **Impacto Financiero:** Costo anual estimado superior a $340,000 USD debido a estos errores.\n",
        "\n",
        "2.  **Definici√≥n de los Datos:**\n",
        "    * El sistema procesar√° √∫nicamente sentencias SQL en formato de texto plano.\n",
        "    * **Importante:** No se almacenar√°n ni procesar√°n datos sensibles de clientes.\n",
        "\n",
        "3.  **Identificaci√≥n de Stakeholders (√Åreas Implicadas):**\n",
        "    * Run the Bank (Operaciones)\n",
        "    * Equipos de bases de datos (Oracle DB, DB2)\n",
        "    * Control Batch (Procesos por lotes)\n",
        "    * Quality Assurance (QA)\n",
        "    * Arquitectura de Datos\n",
        "\n",
        "4.  **Propuesta de Arquitectura y Tecnolog√≠a:**\n",
        "    * **Modelo de IA:** Google Gemini 1.5 Pro a trav√©s de Vertex AI.\n",
        "    * **Backend:** Python 3 con FastAPI.\n",
        "    * **Frontend:** React.\n",
        "    * **Infraestructura:** Docker y un pipeline de CI/CD (Integraci√≥n/Entrega Continua).\n",
        "\n",
        "5.  **An√°lisis de Viabilidad:**\n",
        "    * Estimar un **cronograma** realista para el proyecto.\n",
        "    * Proporcionar una estimaci√≥n de **costos** de implementaci√≥n y mantenimiento.\n",
        "    * Calcular el **Retorno de la Inversi√≥n (ROI)** esperado.\n",
        "\n",
        "---\n",
        "**FIN DEL BRIEF**\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a TU funci√≥n con el prompt de briefing.\n",
        "# Tu funci√≥n 'enviar_mensaje' se encargar√° de procesarlo y mostrar la respuesta.\n",
        "enviar_mensaje(prompt_cot_briefing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "9zKH85fvbswg",
        "outputId": "70c0dc98-2ac1-41f3-82a5-ef8cd8502ea4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #06):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">Brief del proyecto SantanderSQL Shield analizado. Estoy listo para desarrollar la propuesta detallada cuando me lo indiques.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 1452, Respuesta: 23, Total: 1475\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"Ok Vamos a trabajar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "Ox80GmJVcDkV",
        "outputId": "25987565-5a6f-4f39-ca2e-f1562a4010f3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #07):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">¬°Perfecto! Estoy listo para comenzar. ¬øCu√°l es el primer paso o aspecto del proyecto \"SantanderSQL Shield\" en el que te gustar√≠a que trabaj√°ramos juntos?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 1487, Respuesta: 36, Total: 1523\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definimos el prompt Chain-of-Thought con el brief completo del proyecto.\n",
        "prompt_cot_briefing = \"\"\"\n",
        "\n",
        "Paso 1. Diem como propones que implementemos este proyecto\n",
        "Paso 2. Dame un Ejemplo que tecnologias arqutiectura usariamos\n",
        "Paso 3. Dime cual seria el Entregable\n",
        "Paso 4. Dime que podria esperar el usuario Final\n",
        "Paso 5. Dime tus conclusiones, por que elegiste dicho modelo / tecnologia para montar el proyecto\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a TU funci√≥n con el prompt de briefing.\n",
        "# Tu funci√≥n 'enviar_mensaje' se encargar√° de procesarlo y mostrar la respuesta.\n",
        "enviar_mensaje(prompt_cot_briefing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "oAApw-GjcWk_",
        "outputId": "9b4ee028-a206-413c-ef84-916729c072d8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #eaf3fa; color: #000000;\n",
              "                padding: 15px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 700px; line-height: 1.5; font-size: 15px;\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #08):</strong><br>\n",
              "        <div style=\"margin-top: 8px;\">### Paso 1: Propuesta de Implementaci√≥n\n",
              "\n",
              "1. **Fase de Planificaci√≥n:**\n",
              "   - **Reuni√≥n inicial con los stakeholders:** Alinearse con todas las √°reas involucradas para entender sus necesidades espec√≠ficas y desaf√≠os. Establecer el alcance del proyecto.\n",
              "   - **Definici√≥n de requisitos:** Documentar todos los requisitos funcionales y no funcionales.\n",
              "   - **An√°lisis de riesgos:** Identificar potenciales riesgos y definir estrategias de mitigaci√≥n.\n",
              "\n",
              "2. **Dise√±o de la Soluci√≥n:**\n",
              "   - **Arquitectura general:** Dise√±ar una arquitectura que se integre sin problemas con los sistemas existentes de Santander.\n",
              "   - **Modelado de datos:** Establecer c√≥mo se manejar√°n los datos SQL sin comprometer la seguridad.\n",
              "   - **Definici√≥n de flujos de trabajo:** Modelar c√≥mo los scripts DML ser√°n generados, validados y enviados a producci√≥n.\n",
              "\n",
              "3. **Desarrollo:**\n",
              "   - **Implementaci√≥n del backend y frontend:** Utilizar Python con FastAPI para construir el backend y React para el frontend.\n",
              "   - **Integrar el modelo de IA:** Usar Google Gemini 1.5 Pro en Vertex AI para validar y optimizar scripts DML.\n",
              "   - **Configuraci√≥n de infraestructura:** Utilizar Docker para la contenedorizaci√≥n y asegurar un pipeline CI/CD eficiente.\n",
              "\n",
              "4. **Pruebas y Validaci√≥n:**\n",
              "   - **Pruebas unitarias y de integraci√≥n:** Asegurar que cada componente funciona correctamente.\n",
              "   - **Pruebas de carga y rendimiento:** Garantizar que el sistema puede manejar el volumen esperado de solicitudes DML.\n",
              "\n",
              "5. **Despliegue y Monitoreo:**\n",
              "   - **Despliegue gradual:** Implementar la soluci√≥n en entornos de desarrollo, prueba y luego producci√≥n.\n",
              "   - **Monitoreo continuo:** Realizar monitoreo para asegurar la implementaci√≥n exitosa y realizar ajustes seg√∫n sea necesario.\n",
              "\n",
              "### Paso 2: Ejemplo de Tecnolog√≠a y Arquitectura\n",
              "\n",
              "- **Frontend:** React, para crear interfaces de usuario din√°micas y receptivas.\n",
              "- **Backend:** Python 3 con FastAPI, para APIs robustas y escalables.\n",
              "- **Inteligencia Artificial:** Google Gemini 1.5 Pro desplegado en Vertex AI, asegurando una capacidad de aprendizaje y procesamiento avanzada.\n",
              "- **Contenedorizaci√≥n:** Docker, para asegurar la consistencia en todos los entornos.\n",
              "- **CI/CD:** Herramientas como Jenkins para permitir integraci√≥n y entrega continua.\n",
              "\n",
              "### Paso 3: Entregables\n",
              "\n",
              "- **Documentaci√≥n Completa:** Incluir√° diagramas de arquitectura, flujos de trabajo y manuales de usuario.\n",
              "- **C√≥digo Fuente:** Repositorio Git organizado y documentado.\n",
              "- **Sistema en Producci√≥n:** La soluci√≥n \"SantanderSQL Shield\" completamente implementada y en funcionamiento.\n",
              "- **Informe de Evaluaci√≥n:** An√°lisis de rendimiento, ROI esperado y retroalimentaci√≥n de usuarios.\n",
              "\n",
              "### Paso 4: Expectativas del Usuario Final\n",
              "\n",
              "- **Eficiencia Mejorada:** Reducci√≥n en la tasa de errores de solicitudes DML y automatizaci√≥n del proceso de validaci√≥n.\n",
              "- **Interfaz Intuitiva:** Un sistema f√°cil de usar que gu√≠a a los usuarios a trav√©s del proceso de generaci√≥n y validaci√≥n de scripts.\n",
              "- **Soporte T√©cnico:** L√≠neas claras de soporte en caso de dudas o problemas.\n",
              "\n",
              "### Paso 5: Conclusiones\n",
              "\n",
              "- **Elecci√≥n del Modelo de IA:** Google Gemini 1.5 Pro se eligi√≥ por su capacidad para procesar y aprender de grandes vol√∫menes de datos con precisi√≥n, mejorando la validaci√≥n de scripts.\n",
              "- **Elecci√≥n de Tecnolog√≠as:** La combinaci√≥n de FastAPI y React se seleccion√≥ por su capacidad para desarrollar aplicaciones web r√°pidas y escalables, esenciales para manejar el volumen de solicitudes de Santander.\n",
              "- **Contenedorizaci√≥n y CI/CD:** Estas pr√°cticas aseguran que el software se desarrolle, pruebe y despliegue de manera eficiente y consistente, minimizando el tiempo de inactividad y permitiendo iteraciones r√°pidas.\n",
              "\n",
              "Esta estrategia nos permitir√° cumplir con los objetivos del proyecto, minimizando errores y optimizando los procesos internos de Santander US Bank.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 1615, Respuesta: 859, Total: 2474\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"me diste un gran plan podrias darme una lista un resumen breve de cada paso?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "g3cMGAdzd53o",
        "outputId": "be57f3d9-59a1-4e89-ca0c-7f921fd09cd9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #10):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Claro, aqu√≠ tienes un resumen breve de cada paso:\n",
              "\n",
              "1. **Propuesta de Implementaci√≥n:**\n",
              "   - **Planificaci√≥n:** Reuniones con stakeholders, definici√≥n de requisitos, an√°lisis de riesgos.\n",
              "   - **Dise√±o:** Arquitectura del sistema, modelado de datos, flujos de trabajo definidos.\n",
              "   - **Desarrollo:** Backend con Python y FastAPI, frontend con React, integraci√≥n de IA.\n",
              "   - **Pruebas:** Ejecuci√≥n de pruebas unitarias, de integraci√≥n, de carga y rendimiento.\n",
              "   - **Despliegue:** Implementaci√≥n gradual y monitoreo continuo para ajustes.\n",
              "\n",
              "2. **Tecnolog√≠a y Arquitectura:**\n",
              "   - **Frontend:** React.\n",
              "   - **Backend:** Python y FastAPI.\n",
              "   - **Inteligencia Artificial:** Google Gemini 1.5 Pro en Vertex AI.\n",
              "   - **Infraestructura:** Docker para contenedorizaci√≥n y CI/CD con herramientas como Jenkins.\n",
              "\n",
              "3. **Entregables:**\n",
              "   - Documentaci√≥n completa.\n",
              "   - C√≥digo fuente bien documentado.\n",
              "   - Sistema completamente funcional en producci√≥n.\n",
              "   - Informe de evaluaci√≥n del sistema.\n",
              "\n",
              "4. **Expectativas del Usuario Final:**\n",
              "   - **Eficiencia Mejorada:** Menor tasa de errores, validaci√≥n autom√°tica de scripts.\n",
              "   - **Interfaz Intuitiva:** F√°cil de usar.\n",
              "   - **Soporte T√©cnico:** Disponibilidad en caso de dudas.\n",
              "\n",
              "5. **Conclusiones:**\n",
              "   - **Modelo de IA:** Seleccionado por su precisi√≥n y capacidad de aprendizaje.\n",
              "   - **Tecnolog√≠as:** FastAPI y React por su rapidez y capacidad de escalabilidad.\n",
              "   - **Contenedorizaci√≥n y CI/CD:** Aseguran eficiencia y consistencia en despliegues.\n",
              "\n",
              "Este resumen ofrece una visi√≥n general de cada paso del proyecto. Si necesitas m√°s detalles sobre alguno de estos puntos, h√°zmelo saber.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 2884, Respuesta: 381, Total: 3265\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"\"\"\n",
        "\n",
        "Gracias por el resumen. Es un buen inicio, pero para que sea una propuesta s√≥lida, necesitamos ir al grano y justificar dos √°reas clave:\n",
        "\n",
        "Primero, la tecnolog√≠a. La justificaci√≥n para usar Google Gemini es muy gen√©rica. Necesito saber por qu√© es mejor que otras alternativas, como los modelos de OpenAI o incluso un modelo open-source m√°s controlable y econ√≥mico, considerando que nuestra tarea es muy espec√≠fica.\n",
        "\n",
        "Segundo, el plan. Es demasiado vago para un entorno bancario. ¬øC√≥mo mediremos de forma concreta el √©xito m√°s all√° de \"entregar un sistema\"? Y, m√°s importante, ¬øcu√°l es el plan de despliegue exacto para implementarlo de forma segura sin interrumpir las operaciones?\n",
        "\n",
        "Necesitamos respuestas concretas a esas dos preguntas para considerar la inversi√≥n.\n",
        "\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "n7SKsGhbe61v",
        "outputId": "73908bc1-f693-4c18-cfa6-3214e34caf42"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #11):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Entiendo, voy a proporcionar una justificaci√≥n m√°s detallada y concreta para ambas √°reas clave.\n",
              "\n",
              "### Justificaci√≥n de la Tecnolog√≠a\n",
              "\n",
              "1. **Google Gemini 1.5 Pro:**\n",
              "   - **Rendimiento Espec√≠fico:** Google Gemini est√° dise√±ado para trabajar con grandes vol√∫menes de datos y se ha optimizado para tareas espec√≠ficas relacionadas con el procesamiento de lenguaje natural (PLN), lo cual es crucial para la validaci√≥n y generaci√≥n autom√°tica de scripts DML.\n",
              "   - **Integraci√≥n con Infraestructura de Google Cloud:** Como parte de Vertex AI, Google Gemini facilita la integraci√≥n con otros servicios del ecosistema de Google Cloud, permitiendo una f√°cil escalabilidad y gesti√≥n de datos.\n",
              "   - **Seguridad y Cumplimiento:** Google ofrece robustos protocolos de seguridad y cumplimiento, cr√≠ticos para el entorno regulado del sector bancario.\n",
              "   - **Compatibilidad y Soporte:** La integraci√≥n y soporte continuo de Google puede ser superior para un banco de la envergadura de Santander, garantizando actualizaciones y mantenimiento regular.\n",
              "\n",
              "2. **Comparaci√≥n con alternativas:**\n",
              "   - **Modelos de OpenAI:** Aunque avanzados, pueden presentar limitaciones en t√©rminos de personalizaci√≥n y control de datos, adem√°s de consideraciones de costos en uso continuo a escala.\n",
              "   - **Modelos Open-Source:** Si bien permiten un mayor control, pueden requerir m√°s recursos para su adaptaci√≥n, optimizaci√≥n y mantenimiento, adem√°s de posiblemente ofrecer menor rendimiento en tareas espec√≠ficas de PLN sin adecuadas personalizaciones.\n",
              "\n",
              "### Plan de Despliegue Seguro\n",
              "\n",
              "1. **Medici√≥n del √âxito:**\n",
              "   - **Reducci√≥n de la Tasa de Error:** Objetivo de disminuir la tasa de errores de solicitudes DML del 18% a menos del 5% en el primer a√±o.\n",
              "   - **Ahorro de Costos:** Reducir el impacto financiero de los errores a menos de $100,000 USD anualmente.\n",
              "   - **Tiempo de Procesamiento:** Mejora en la eficiencia del proceso de validaci√≥n, reduciendo el tiempo desde la solicitud hasta la producci√≥n en un 30%.\n",
              "\n",
              "2. **Plan de Despliegue:**\n",
              "   - **Despliegue por Fases:** Implementaci√≥n gradual comenzando con un ambiente de pruebas controlado para asegurar la estabilidad del sistema.\n",
              "   - **Ambientaci√≥n Piloto:** Ejecutar un piloto con un subconjunto de usuarios y operaciones cr√≠ticas para recoger comentarios y detener cualquier problema antes del despliegue completo.\n",
              "   - **Revisiones de Seguridad:** Auditor√≠as exhaustivas y revisiones de seguridad antes y despu√©s de cada fase de implementaci√≥n.\n",
              "   - **Entrenamiento y Documentaci√≥n:** Capacitar a los usuarios y personal t√©cnico sobre el nuevo sistema y su utilizaci√≥n.\n",
              "   - **Retroalimentaci√≥n Continua:** Incorporar mejoras basadas en la retroalimentaci√≥n del usuario final y del equipo t√©cnico.\n",
              "\n",
              "Estas decisiones proporcionan una confianza adicional en la inversi√≥n, alineando tanto las implementaciones t√©cnicas como las operativas con los objetivos estrat√©gicos y regulatorios de Santander US Bank.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 3435, Respuesta: 617, Total: 4052\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Iteraciones con el LLM empleando User_Prompt Tree-of-Thoughts (ToT)**"
      ],
      "metadata": {
        "id": "5PQU4HzlfZOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt ToT que rechaza la justificaci√≥n y fuerza la exploraci√≥n de 3 alternativas de LLM.\n",
        "user_prompt_tot_analisis_llm = \"\"\"\n",
        "Agradezco la aclaraci√≥n, sin embargo, la justificaci√≥n para seleccionar a Google Gemini como √∫nica opci√≥n a√∫n no es concluyente y parece m√°s una defensa de la propuesta inicial que un an√°lisis cr√≠tico. La decisi√≥n sobre el motor de IA es el n√∫cleo de este proyecto y no podemos proceder con una √∫nica alternativa sin un an√°lisis comparativo m√°s profundo.\n",
        "\n",
        "Por ello, vamos a utilizar un enfoque de **'√Årbol de Pensamientos' (Tree-of-Thoughts)** para explorar las opciones de manera estructurada.\n",
        "\n",
        "**Tu tarea es la siguiente:**\n",
        "\n",
        "Quiero que generes una descripci√≥n para tres \"ramas\" de decisi√≥n, cada una centrada en un tipo de modelo de LLM. Las ramas a explorar son:\n",
        "\n",
        "1.  **Rama 1: Ecosistema Google (Gemini 1.5 Pro en Vertex AI).**\n",
        "2.  **Rama 2: Ecosistema OpenAI (GPT-4o o el modelo m√°s avanzado disponible).**\n",
        "3.  **Rama 3: Soluci√≥n Soberana (un modelo Open-Source de alto rendimiento como Llama 3 o similar, que ser√≠a fine-tuneado y alojado en nuestra propia infraestructura).**\n",
        "\n",
        "---\n",
        "\n",
        "Para cada una de estas tres ramas, debes proporcionar la siguiente informaci√≥n de manera concisa:\n",
        "\n",
        "* **Descripci√≥n Breve:** ¬øQu√© es y cu√°l es su propuesta de valor principal en el mercado?\n",
        "* **Pro (Ventaja Clave):** ¬øCu√°l es su **mayor fortaleza** para nuestro caso de uso espec√≠fico en Santander?\n",
        "* **Contra (Desventaja Clave):** ¬øCu√°l es su **principal debilidad o riesgo** para un entorno bancario regulado como el nuestro?\n",
        "* **Aplicaci√≥n Pr√°ctica:** ¬øC√≥mo funcionar√≠a espec√≠ficamente para nuestra herramienta 'SantanderSQL Shield'? Describe brevemente c√≥mo generar√≠a y validar√≠a queries de manera segura en este escenario.\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a tu funci√≥n con el nuevo prompt ToT.\n",
        "enviar_mensaje(user_prompt_tot_analisis_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "GVd_9yNPf3JC",
        "outputId": "7dc130b3-8ef4-4f70-97b2-dc68887e4b78"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #12):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Entendido, describir√© cada rama seg√∫n el enfoque del \"√Årbol de Pensamientos\" para que puedas evaluar las opciones de manera estructurada.\n",
              "\n",
              "### Rama 1: Ecosistema Google (Gemini 1.5 Pro en Vertex AI)\n",
              "\n",
              "- **Descripci√≥n Breve:**\n",
              "  - Google Gemini 1.5 Pro es un modelo de lenguaje avanzado integrado en la plataforma Vertex AI de Google Cloud. Est√° dise√±ado para tareas complejas de procesamiento del lenguaje natural y aprendizaje autom√°tico con capacidades de integraci√≥n y escalabilidad dentro del ecosistema de Google.\n",
              "\n",
              "- **Pro (Ventaja Clave):**\n",
              "  - **Integraci√≥n y Escalabilidad:** Ofrece una integraci√≥n fluida con otras herramientas de Google Cloud y la infraestructura existente de la empresa, garantizando escalabilidad y soporte t√©cnico eficiente.\n",
              "\n",
              "- **Contra (Desventaja Clave):**\n",
              "  - **Dependencia del Proveedor:** La dependencia en un ecosistema propietario puede llevar a restricciones en la personalizaci√≥n y potenciales costos a largo plazo.\n",
              "\n",
              "- **Aplicaci√≥n Pr√°ctica:**\n",
              "  - Gemini procesar√≠a las solicitudes DML y las validar√≠a con algoritmos avanzados de PLN. Usar√≠a modelos preentrenados ajustados al contexto de banca para prever errores y optimizar queries, con una infraestructura segura y escalable en Google Cloud.\n",
              "\n",
              "### Rama 2: Ecosistema OpenAI (GPT-4 o el m√°s avanzado)\n",
              "\n",
              "- **Descripci√≥n Breve:**\n",
              "  - GPT-4 es parte del ecosistema de OpenAI, conocido por su capacidad para entender y generar texto similar al humano con precisi√≥n en un amplio rango de tareas de lenguaje.\n",
              "\n",
              "- **Pro (Ventaja Clave):**\n",
              "  - **Precisi√≥n y Versatilidad:** Modelos como GPT-4 son reconocidos por su versatilidad para diferentes tipos de lenguaje y pueden ajustarse para diversas aplicaciones con alto rendimiento.\n",
              "\n",
              "- **Contra (Desventaja Clave):**\n",
              "  - **Costos y Control:** Potencialmente altos costos de uso y menor control sobre el procesamiento de datos, factores cr√≠ticos para el manejo de datos sensibles en banca.\n",
              "\n",
              "- **Aplicaci√≥n Pr√°ctica:**\n",
              "  - GPT-4 podr√≠a ser utilizado para generar, revisar y validar scripts DML, identificando errores comunes y proporcionando sugerencias, desplegado en un entorno seguro a trav√©s de APIs de OpenAI.\n",
              "\n",
              "### Rama 3: Soluci√≥n Soberana (Modelo Open-Source/Int. Llama 3)\n",
              "\n",
              "- **Descripci√≥n Breve:**\n",
              "  - Modelos Open-Source como Llama 3 permiten un alto grado de personalizaci√≥n y control, ya que pueden ser ajustados para tareas espec√≠ficas y alojados en infraestructura propia.\n",
              "\n",
              "- **Pro (Ventaja Clave):**\n",
              "  - **Control Total y Costos Reducidos:** Al alojar el modelo internamente, existe un control total sobre los datos y la personalizaci√≥n del modelo a necesidades exactas, adem√°s de potenciales ahorros significativos.\n",
              "\n",
              "- **Contra (Desventaja Clave):**\n",
              "  - **Mayores Requerimientos T√©cnicos:** Requiere un equipo t√©cnico capacitado para el ajuste fino, mantenimiento y actualizaci√≥n del modelo.\n",
              "\n",
              "- **Aplicaci√≥n Pr√°ctica:**\n",
              "  - Un modelo como Llama 3 puede ser fine-tuneado con datos espec√≠ficos de la organizaci√≥n para detectar y corregir errores en scripts DML, implementado de forma segura en los servidores propios del banco.\n",
              "\n",
              "Este an√°lisis conciso debe ayudarte a considerar cu√°l es la mejor opci√≥n en t√©rminos de integraci√≥n, riesgo y coste para la herramienta \"SantanderSQL Shield\".</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 4446, Respuesta: 721, Total: 5167\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt ToT que rechaza la justificaci√≥n y fuerza la exploraci√≥n de 3 alternativas de LLM.\n",
        "user_prompt_tot_analisis_llm = \"\"\"\n",
        "\n",
        "Gracias por el desglose. Es √∫til, pero mi opini√≥n es que en las tres ramas la seguridad se trata como una caracter√≠stica,\n",
        "no como el pilar fundamental que es para un banco. Esto me preocupa.\n",
        "\n",
        "Confiar ciegamente en la \"infraestructura segura\" de Google o en las APIs de OpenAI no es una estrategia; es una vulnerabilidad esperando a ser explotada,\n",
        "ya que nuestros scripts son propiedad intelectual cr√≠tica. Por otro lado, la \"soluci√≥n soberana\" no es inherentemente segura; solo transfiere toda la responsabilidad a nuestro equipo, lo que puede ser a√∫n m√°s arriesgado.\n",
        "\n",
        "Por lo tanto, el desaf√≠o es el siguiente: Para cada una de las tres ramas, quiero que propongas una medida de seguridad t√©cnica y\n",
        "espec√≠fica para mitigar el riesgo principal que presenta. No me digas que es seguro, dime c√≥mo lo har√≠amos seguro en la pr√°ctica.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a tu funci√≥n con el nuevo prompt ToT.\n",
        "enviar_mensaje(user_prompt_tot_analisis_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "jfU8TdXbgT_R",
        "outputId": "686bbcb9-523c-409d-fa35-5b47413fde27"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #13):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Entiendo tus preocupaciones y te proporciono una medida de seguridad t√©cnica espec√≠fica para cada rama que aborde los riesgos potenciales.\n",
              "\n",
              "### Rama 1: Ecosistema Google (Gemini 1.5 Pro en Vertex AI)\n",
              "\n",
              "- **Medida de Seguridad:**\n",
              "  - **Cifrado de Datos y Accesos Restringidos:**\n",
              "    - **Implementaci√≥n:** Utilizar cifrado de datos tanto en tr√°nsito como en reposo. Implementar el cifrado de extremo a extremo para los scripts DML, asegurando que solo personal autorizado pueda acceder y desencriptar estos datos dentro del sistema.\n",
              "    - **Accesos Restringidos:** Configurar roles y pol√≠ticas de acceso detallados en Google Cloud IAM (Identity and Access Management) para garantizar que solo las personas y servicios necesarios tengan acceso al modelo y a los datos procesados. Revisar y auditar regularmente los accesos.\n",
              "\n",
              "### Rama 2: Ecosistema OpenAI (GPT-4)\n",
              "\n",
              "- **Medida de Seguridad:**\n",
              "  - **Anonimizaci√≥n y Pseudonimizaci√≥n de Datos:**\n",
              "    - **Implementaci√≥n:** Antes de enviar cualquier script DML a trav√©s de las APIs de OpenAI, aplicar procesos de anonimizaci√≥n y pseudonimizaci√≥n para eliminar cualquier informaci√≥n sensible o propietaria. Esto implica transformar datos directos en pseudoc√≥digos que OpenAI pueda procesar sin comprometer la seguridad de la informaci√≥n.\n",
              "    - **Canales Seguros:** Asegurar que todas las comunicaciones con las APIs se realicen a trav√©s de canales TLS/SSL seguros para proteger los datos en tr√°nsito.\n",
              "\n",
              "### Rama 3: Soluci√≥n Soberana (Modelo Open-Source/Int. Llama 3)\n",
              "\n",
              "- **Medida de Seguridad:**\n",
              "  - **Seguridad Multicapa y Auditor√≠as Internas:**\n",
              "    - **Implementaci√≥n:** Desplegar el modelo en un entorno de alta seguridad dentro de una red de acceso definido (firewall dentro de un DMZ espec√≠fico) para protegerlo de accesos no autorizados. Configurar capas adicionales de monitoreo de seguridad, como sistemas de detecci√≥n de intrusos (IDS/IPS) para identificar y responder a actividades sospechosas.\n",
              "    - **Auditor√≠as:** Implementar un sistema de auditor√≠as regulares del c√≥digo fuente y la infraestructura para asegurar la integridad y cumplimiento de las pol√≠ticas de seguridad. Adem√°s, realizar revisiones de permisos y accesos regularmente.\n",
              "\n",
              "Estas medidas de seguridad no solo mitigan riesgos inherentes a cada modelo o soluci√≥n, sino que priorizan la protecci√≥n de la propiedad intelectual y la integridad de datos cr√≠ticos para el banco.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 5364, Respuesta: 533, Total: 5897\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"Gracias por el apoyo, lo reviso con nuestro jefe y seguimos discutiendo, bonita noche\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "tLxycT5ngjF5",
        "outputId": "7a424acf-68ef-4c5e-d5b6-37843d7b8ffc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #14):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">¬°De nada! Espero que la informaci√≥n te sea √∫til para la discusi√≥n. Si tienes m√°s preguntas o necesitas m√°s ayuda en el futuro, no dudes en dec√≠rmelo. ¬°Que tengas una buena noche!</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 5924, Respuesta: 42, Total: 5966\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}