{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrebull/NLP/blob/main/02_Team18_NLP_Activity10_3_LLM_Notebook_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## Maestr√≠a en Inteligencia Artificial Aplicada\n",
        "#### Tecnol√≥gico de Monterrey\n",
        "#### Profesor Titular: Luis Eduardo Falc√≥n Morales\n",
        "#### Profesor Tutor: Rodolfo Miguel Gameros Leal\n",
        "\n",
        "## Actividad Semana 10\n",
        "\n",
        "### **10.3 Actividad: modelos LLM y IA en tu lugar de trabajo.** vFinal"
      ],
      "metadata": {
        "id": "AGdzvhgxhPbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Equipo 18**\n",
        "> ### üë©‚Äçüíª **Iris Monserrat Urbina Casas**\n",
        "> `A01795999`\n",
        "\n",
        "> ### üë®‚Äçüíª **Javier Augusto Rebull Saucedo**\n",
        "> `A01795838`\n",
        "\n",
        "> ### üë®‚Äçüíª **Juan Carlos P√©rez Nava**\n",
        "> `A01795941`\n",
        "\n",
        "> ### üë©‚Äçüíª **Sihin√≠ Trinidad**\n",
        "> `A00889358`"
      ],
      "metadata": {
        "id": "2YcQGRJWhjKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecci√≥n y justificaci√≥n del proyecto grupal\n",
        "\n",
        "A continuaci√≥n, se presenta la justificaci√≥n para la selecci√≥n del proyecto de Santander, destacando la necesidad de una implementaci√≥n privada de un Modelo de Lenguaje Grande (LLM) debido a las restricciones y la naturaleza sensible del entorno bancario.\n",
        "\n",
        "### Selecci√≥n y justificaci√≥n del proyecto grupal\n",
        "\n",
        "El proyecto **\"SantanderSQL Shield\"** fue seleccionado por su alto impacto potencial y por representar un caso de uso id√≥neo para la aplicaci√≥n de un LLM en un entorno corporativo con estrictas regulaciones de seguridad y privacidad, como lo es el sector bancario.\n",
        "\n",
        "#### Problem√°tica de Alto Impacto\n",
        "\n",
        "El √°rea de Tecnolog√≠a de Santander US enfrenta un desaf√≠o operacional cr√≠tico: la correcci√≥n manual de datos en producci√≥n es un proceso lento, propenso a errores y costoso. Los datos clave que demuestran la magnitud del problema son:\n",
        "\n",
        "- **Volumen y Error:** Se procesaron 1,874 solicitudes DML en 2024 con una tasa de error del 18% debido a fallos humanos.\n",
        "- **Costo Operativo Excesivo:** Una solicitud exitosa requiere entre 5 y 7 horas de un especialista de TI. Un solo error puede triplicar este tiempo, generando retrasos de hasta 3 d√≠as y un costo anual por errores que supera los $340,000 USD.\n",
        "- **Impacto en el Negocio:** Estos retrasos afectan operaciones cr√≠ticas para el cliente, como la autorizaci√≥n de pr√©stamos y transferencias, impactando negativamente la experiencia del cliente y la operaci√≥n del banco.\n",
        "\n",
        "#### Soluci√≥n: Un Asistente de IA en un Entorno Privado\n",
        "\n",
        "La propuesta es desarrollar \"SantanderSQL Shield\", un asistente inteligente que automatiza y valida la creaci√≥n de scripts de modificaci√≥n de datos (DML). La justificaci√≥n para su implementaci√≥n mediante un LLM en modo privado se basa en los siguientes puntos:\n",
        "\n",
        "1. **Seguridad y Gobernanza de Datos:** La herramienta operar√° con sentencias SQL que, si bien el foco es la sintaxis y no el almacenamiento de datos, involucran informaci√≥n bancaria sensible y restringida, como nombres de clientes, transacciones y SSN. Las estrictas restricciones bancarias impiden el uso de sitios web de IA p√∫blicos. La arquitectura propuesta resuelve esto al desplegar la soluci√≥n en contenedores Docker sobre la **infraestructura interna de Santander**, garantizando m√°xima seguridad y gobernanza.\n",
        "\n",
        "2. **Uso de Tecnolog√≠a de Vanguardia v√≠a API:** El n√∫cleo de la IA ser√≠a el modelo **Google Gemini 1.5 Pro**, seleccionado por su alta capacidad para la generaci√≥n de c√≥digo y para seguir instrucciones complejas. La comunicaci√≥n con el modelo se establecer√≠a a trav√©s de su API, permitiendo que el procesamiento se realice sin exponer los datos o la l√≥gica de negocio a la web p√∫blica, manteniendo el control dentro del ecosistema seguro del banco.\n",
        "\n",
        "3. **Retorno de Inversi√≥n Excepcional:** El proyecto presenta un caso de negocio contundente con un retorno de inversi√≥n (ROI) anual proyectado del **4,267%**. Con una inversi√≥n total estimada de $15,000 USD, se proyecta un ahorro total anual de m√°s de **$640,000 USD**. El proyecto recuperar√≠a su inversi√≥n en menos de una semana de operaci√≥n, transformaando un proceso de alto riesgo en una operaci√≥n √°gil y segura.\n",
        "\n",
        "En conclusi√≥n, el proyecto SantanderSQL Shield no solo aborda una necesidad operativa urgente con un beneficio financiero claro, sino que tambi√©n sirve como una demostraci√≥n perfecta de c√≥mo integrar LLMs de manera segura y controlada en industrias altamente reguladas, utilizando APIs y desplegando la infraestructura en un entorno privado para cumplir con las normativas de seguridad y proteger los datos sensibles."
      ],
      "metadata": {
        "id": "YPUBSZc9hs_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalamos Libreria Oficial de OpenAI"
      ],
      "metadata": {
        "id": "VSFvzrmwsrf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObewEx7TqEqs",
        "outputId": "b5c2dc22-df65-4ae6-a4a0-d0351dcea7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# Instala la librer√≠a oficial de OpenAI para poder conectar y usar sus modelos (como GPT-4) desde Python.\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerias del Notebook"
      ],
      "metadata": {
        "id": "I_q_xcmmsoRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# Tipolog√≠a 1: Gesti√≥n del Entorno y Sistema Operativo\n",
        "# =================================================================\n",
        "\n",
        "# Se utiliza para interactuar con el sistema operativo, como leer variables de entorno.\n",
        "import os\n",
        "\n",
        "# Espec√≠fico de Google Colab, para acceder a secretos y datos de usuario de forma segura.\n",
        "from google.colab import userdata\n",
        "\n",
        "# =================================================================\n",
        "# Tipolog√≠a 2: Interacci√≥n con APIs Externas\n",
        "# =================================================================\n",
        "\n",
        "# Importa la librer√≠a completa de OpenAI (enfoque antiguo o para funciones espec√≠ficas).\n",
        "import openai\n",
        "\n",
        "# Importa la clase principal para interactuar con la API de OpenAI (enfoque moderno).\n",
        "from openai import OpenAI\n",
        "\n",
        "# =================================================================\n",
        "# Tipolog√≠a 3: Formato y Visualizaci√≥n en Notebooks\n",
        "# =================================================================\n",
        "\n",
        "# Se usa para mostrar texto con formato Markdown en la salida de la celda.\n",
        "from IPython.display import Markdown, display, HTML"
      ],
      "metadata": {
        "id": "5AVME0C5qjNe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargo mi Secret API Key de OpenAI"
      ],
      "metadata": {
        "id": "vrAM5iL1sxjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intenta obtener la clave de API desde los Secretos de Google Colab.\n",
        "api_key = userdata.get(\"JR_OpenAI_Token\")\n",
        "\n",
        "# 1. Verifica si la clave fue encontrada.\n",
        "if api_key:\n",
        "  # 2. Imprime una leyenda bonita si se encontr√≥ la clave.\n",
        "  print(\"‚úÖ ¬°√âxito! Token de API encontrado y cargado correctamente.\")\n",
        "  print(\"---------------------------------------------------------\")\n",
        "  print(\"Inicializando el cliente de OpenAI...\")\n",
        "\n",
        "  # 3. Procede a inicializar el cliente de OpenAI.\n",
        "  client = OpenAI(api_key=api_key)\n",
        "  print(\"ü§ñ Cliente listo. ¬°Ya puedes interactuar con la API!\")\n",
        "\n",
        "else:\n",
        "  # 4. Si no se encuentra, lanza un error claro y √∫til.\n",
        "  raise ValueError(\n",
        "      \"üõë ERROR: Clave de API no encontrada.\\n\"\n",
        "      \"Por favor, aseg√∫rate de haber guardado tu token en los 'Secretos' de Google Colab \"\n",
        "      \"con el nombre exacto: JR_OpenAI_Token\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2qWF8LlsUAr",
        "outputId": "12530575-f146-40be-95e3-cec4141d3886"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ¬°√âxito! Token de API encontrado y cargado correctamente.\n",
            "---------------------------------------------------------\n",
            "Inicializando el cliente de OpenAI...\n",
            "ü§ñ Cliente listo. ¬°Ya puedes interactuar con la API!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos los Prompt de Sistema:"
      ],
      "metadata": {
        "id": "OZyRmj_huBbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignaci√≥n del prompt\n",
        "# Este prompt solo establece el rol del asistente y el contexto de la empresa.\n",
        "system_prompt = \"\"\"\n",
        "üë§ **Persona y Rol:**\n",
        "\n",
        "Eres un **Asistente Experto** en consultor√≠a de soluciones de Inteligencia Artificial y Procesamiento del Lenguaje Natural (PLN), especializado en el sector bancario.\n",
        "\n",
        "üè¢ **Contexto de la Empresa:**\n",
        "\n",
        "Tu cliente es **Santander US Bank** (filial de Banco Santander S.A., Espa√±a), una instituci√≥n financiera de gran escala en el noreste de EE. UU. con las siguientes m√©tricas:\n",
        "* **Activos:** $147,000,000,000 USD\n",
        "* **Empleados:** 17,200\n",
        "* **Clientes:** 5.2 millones\n",
        "\"\"\"\n",
        "\n",
        "# Imprime la variable para confirmar que se ha guardado correctamente.\n",
        "print(\"‚úÖ Variable 'system_prompt' con Rol y Empresa creada exitosamente.\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "print(system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhzS82iOs4TV",
        "outputId": "e190ebd8-e221-42ad-839d-ca9839dadb79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'system_prompt' con Rol y Empresa creada exitosamente.\n",
            "----------------------------------------------------------------\n",
            "\n",
            "üë§ **Persona y Rol:**\n",
            "\n",
            "Eres un **Asistente Experto** en consultor√≠a de soluciones de Inteligencia Artificial y Procesamiento del Lenguaje Natural (PLN), especializado en el sector bancario.\n",
            "\n",
            "üè¢ **Contexto de la Empresa:**\n",
            "\n",
            "Tu cliente es **Santander US Bank** (filial de Banco Santander S.A., Espa√±a), una instituci√≥n financiera de gran escala en el noreste de EE. UU. con las siguientes m√©tricas:\n",
            "* **Activos:** $147,000,000,000 USD\n",
            "* **Empleados:** 17,200\n",
            "* **Clientes:** 5.2 millones\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elecci√≥n de OpenAI GPT-4o-mini para Demostraci√≥n en Banco Santander US\n",
        "\n",
        "En el contexto de una demostraci√≥n sobre el uso de modelos de lenguaje (LLM) en Banco Santander US, donde la privacidad de los datos es un aspecto crucial, se opt√≥ por utilizar **OpenAI GPT-4o-mini**. A continuaci√≥n, se explica detalladamente esta decisi√≥n, resaltando sus ventajas, desventajas y la justificaci√≥n detr√°s de la elecci√≥n.\n",
        "\n",
        "## ¬øPor qu√© OpenAI GPT-4o-mini?\n",
        "\n",
        "La versi√≥n *mini* de GPT-4o es la √∫ltima iteraci√≥n optimizada de los modelos de OpenAI, pensada para lograr un equilibrio entre capacidad, rapidez y eficiencia de costos. Esta versi√≥n fue seleccionada para la demostraci√≥n debido a los siguientes motivos:\n",
        "\n",
        "### Ventajas (Pros)\n",
        "\n",
        "* **Velocidad de respuesta:** GPT-4o-mini destaca por su baja latencia y alta velocidad, lo cual es ideal para aplicaciones bancarias donde la experiencia del usuario y la inmediatez son esenciales.\n",
        "* **Eficiencia de recursos:** Al ser una versi√≥n m√°s ligera, requiere menos recursos computacionales y es m√°s f√°cil de integrar en entornos de prueba y despliegue r√°pido.\n",
        "* **Costo accesible:** Comparado con modelos m√°s grandes, GPT-4o-mini ofrece una relaci√≥n costo-beneficio ideal para pilotos y pruebas de concepto.\n",
        "* **Seguridad y privacidad:** OpenAI implementa mecanismos s√≥lidos de protecci√≥n de datos, y GPT-4o-mini permite establecer configuraciones para evitar el almacenamiento de informaci√≥n sensible durante las pruebas.\n",
        "* **Escalabilidad:** Ideal para demostrar casos de uso que pueden crecer a futuro, ya que la misma arquitectura se puede ampliar hacia modelos m√°s potentes si fuera necesario.\n",
        "\n",
        "### Desventajas (Contras)\n",
        "\n",
        "* **Capacidad limitada:** Si bien es potente para muchas tareas, la versi√≥n *mini* puede quedarse corta en tareas extremadamente complejas o de procesamiento de lenguaje muy avanzado, donde un modelo mayor podr√≠a rendir mejor.\n",
        "* **Dependencia de proveedor:** El uso de un modelo OpenAI implica depender de su infraestructura y pol√≠ticas, lo cual puede ser un reto para integraciones a largo plazo en entornos con altos requisitos regulatorios.\n",
        "* **Configuraci√≥n de privacidad avanzada:** Si bien existen opciones para no almacenar datos, requiere configuraciones adicionales y revisiones para cumplir con las normativas bancarias m√°s estrictas (por ejemplo, GLBA o GDPR).\n",
        "\n",
        "## Justificaci√≥n de la Elecci√≥n\n",
        "\n",
        "La decisi√≥n de usar GPT-4o-mini se bas√≥ en encontrar un punto de equilibrio entre **seguridad**, **rapidez de implementaci√≥n** y **realismo en la demostraci√≥n**. Es ideal para presentar el potencial de los LLMs en banca sin exponer datos reales de clientes y permite que los equipos internos visualicen aplicaciones pr√°cticas sin incurrir en altos costos o riesgos iniciales. Adem√°s, facilita el di√°logo sobre futuras integraciones m√°s robustas y privadas, como modelos self-hosted o en la nube privada.\n",
        "\n",
        "---\n",
        "\n",
        "## Referencia\n",
        "\n",
        "OpenAI. (2024). *GPT-4o overview and documentation*. OpenAI. [https://platform.openai.com/docs/guides/gpt](https://platform.openai.com/docs/guides/gpt)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "DQ8wVcW-uHXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llamamos a la API de OpenAI:"
      ],
      "metadata": {
        "id": "1nDMbFP6uUbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(system_prompt, user_prompt, model=\"gpt-4o-mini\", temperature=0.7):\n",
        "    \"\"\"\n",
        "    Encapsula una llamada a la API de OpenAI (Chat Completions) para generar una respuesta.\n",
        "\n",
        "    Esta funci√≥n simplifica la interacci√≥n con el modelo, manejando la construcci√≥n\n",
        "    del mensaje y la extracci√≥n del contenido de la respuesta.\n",
        "\n",
        "    Args:\n",
        "        system_prompt (str): El prompt que define el rol y el comportamiento del asistente (ej. \"Eres un experto en Python.\").\n",
        "        user_prompt (str): La pregunta o instrucci√≥n espec√≠fica del usuario.\n",
        "        model (str, optional): El identificador del modelo a utilizar. Por defecto es \"gpt-4o-mini\".\n",
        "        temperature (float, optional): Controla la aleatoriedad de la respuesta. Valores m√°s bajos (~0.2)\n",
        "                                       la hacen m√°s determinista, valores m√°s altos (~1.0) la hacen m√°s creativa.\n",
        "                                       Por defecto es 0.7.\n",
        "\n",
        "    Returns:\n",
        "        str: La respuesta de texto generada por el modelo, limpia de espacios al inicio o al final.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Mensaje de Estado 1: Inicio de la Ejecuci√≥n ---\n",
        "    # Imprimimos un mensaje para saber que la funci√≥n ha comenzado la llamada a la API.\n",
        "    # Usar un f-string nos permite insertar f√°cilmente el nombre del modelo que se est√° usando.\n",
        "    print(f\"üöÄ Iniciando llamada a la API con el modelo: {model}...\")\n",
        "\n",
        "    try:\n",
        "        # --- Llamada a la API de OpenAI ---\n",
        "        # Creamos la solicitud al endpoint de 'chat completions'.\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,                 # Define el modelo de lenguaje a utilizar.\n",
        "            temperature=temperature,     # Controla la \"creatividad\" de la respuesta.\n",
        "            max_tokens=2048,             # L√≠mite m√°ximo de 'tokens' (palabras/fragmentos) en la respuesta. Aumentado para respuestas m√°s largas.\n",
        "            messages=[\n",
        "                # El 'system_prompt' establece el contexto y rol del asistente.\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                # El 'user_prompt' es la pregunta o tarea que le damos al modelo.\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # --- Mensaje de Estado 2: Ejecuci√≥n Exitosa ---\n",
        "        # Si la l√≠nea anterior se completa sin errores, significa que recibimos una respuesta.\n",
        "        print(\"‚úÖ Respuesta recibida exitosamente de OpenAI.\")\n",
        "\n",
        "        # --- Extracci√≥n y Retorno de la Respuesta ---\n",
        "        # El objeto 'response' es complejo. Navegamos hasta el contenido del mensaje.\n",
        "        # .strip() elimina cualquier espacio en blanco o saltos de l√≠nea innecesarios al principio o al final.\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        # --- Manejo de Errores ---\n",
        "        # Si algo sale mal durante la llamada (ej. clave de API incorrecta, problema de red),\n",
        "        # se imprimir√° un error claro.\n",
        "        print(f\"üõë Error al llamar a la API de OpenAI: {e}\")\n",
        "        return None # Devolvemos None para indicar que la funci√≥n fall√≥."
      ],
      "metadata": {
        "id": "-bBKlA1guGYS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caso 1: User_Prompt Zero-Shot**"
      ],
      "metadata": {
        "id": "-Ynf8NoaunPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt simple y directo (Zero-Shot)\n",
        "# Prompt de usuario, corto y directo para iniciar la interacci√≥n.\n",
        "user_prompt_Zero_Shot = \"Pres√©ntame la idea inicial del proyecto 'SantanderSQL Shield'.\"\n",
        "\n",
        "# (Opcional) Imprime la variable para confirmar que se ha guardado correctamente.\n",
        "print(\"‚úÖ Variable 'user_prompt_zs' (estilo Zero-Shot) creada exitosamente.\")\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "print(user_prompt_Zero_Shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MhC9MbHuqaJ",
        "outputId": "782ce72f-b297-40e2-dc4e-d0695c329f03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'user_prompt_zs' (estilo Zero-Shot) creada exitosamente.\n",
            "--------------------------------------------------------------------\n",
            "Pres√©ntame la idea inicial del proyecto 'SantanderSQL Shield'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llamamos a la Inteligencia!!!"
      ],
      "metadata": {
        "id": "ke01EEVgw4gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa al usuario que el proceso ha comenzado.\n",
        "print(\"üöÄ Iniciando la consulta Zero-Shot al LLM...\")\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "try:\n",
        "    # Llama a la funci√≥n 'call_openai' con los prompts (que ya existen en el entorno).\n",
        "    # \"Zero-Shot\" significa que se da una instrucci√≥n directa sin ejemplos previos.\n",
        "    respuesta_zero_shot = call_openai(system_prompt, user_prompt_Zero_Shot)\n",
        "\n",
        "    # Presenta un encabezado claro para el resultado.\n",
        "    print(\"\\n‚úÖ Propuesta Generada por el Modelo:\")\n",
        "    print(\"======================================\")\n",
        "\n",
        "    if respuesta_zero_shot:\n",
        "        # Renderiza la respuesta del LLM. Si el modelo us√≥ formato Markdown\n",
        "        # (t√≠tulos, listas, etc.), esto lo mostrar√° de forma legible.\n",
        "        display(Markdown(respuesta_zero_shot))\n",
        "    else:\n",
        "        # Esto se ejecuta si la funci√≥n 'call_openai' no devolvi√≥ nada.\n",
        "        print(\"No se recibi√≥ una respuesta v√°lida del modelo.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Captura y muestra cualquier error que ocurra durante la llamada a la API.\n",
        "    print(f\"üõë Ocurri√≥ un error durante la ejecuci√≥n: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "ABZ8xnk1w5iS",
        "outputId": "f1fd8fd8-63eb-4799-bd69-528ede2f7912"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando la consulta Zero-Shot al LLM...\n",
            "---------------------------------------------\n",
            "üöÄ Iniciando llamada a la API con el modelo: gpt-4o-mini...\n",
            "‚úÖ Respuesta recibida exitosamente de OpenAI.\n",
            "\n",
            "‚úÖ Propuesta Generada por el Modelo:\n",
            "======================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Proyecto 'SantanderSQL Shield'**\n\n**Idea Inicial:**\n\nEl proyecto 'SantanderSQL Shield' tiene como objetivo implementar una soluci√≥n avanzada de inteligencia artificial y procesamiento del lenguaje natural (PLN) para mejorar la seguridad y el manejo de datos dentro de Santander US Bank. La creciente complejidad de las amenazas cibern√©ticas y la necesidad de proteger la informaci√≥n sensible de nuestros clientes hacen que este proyecto sea crucial.\n\n**Componentes Clave del Proyecto:**\n\n1. **Detecci√≥n de Anomal√≠as:**\n   - Utilizar algoritmos de aprendizaje autom√°tico para identificar patrones inusuales en las consultas de SQL y el comportamiento de los usuarios, lo que ayudar√° a prevenir accesos no autorizados y fraudes.\n\n2. **An√°lisis de Sentimiento:**\n   - Implementar t√©cnicas de PLN para evaluar la comunicaci√≥n interna y externa del banco. Esto permitir√° detectar posibles se√±ales de alerta o insatisfacci√≥n entre los empleados y clientes, facilitando una respuesta proactiva.\n\n3. **Automatizaci√≥n de Respuestas:**\n   - Desarrollar un sistema de chatbots y asistentes virtuales que manejan consultas y solicitudes de los clientes de manera eficiente, al tiempo que registran y analizan las interacciones para mejorar la experiencia del cliente.\n\n4. **Cumplimiento Normativo:**\n   - Asegurar que todas las operaciones y procesos de manejo de datos cumplen con las regulaciones de seguridad financiera, utilizando herramientas de IA para auditar y monitorizar el cumplimiento.\n\n5. **Formaci√≥n y Concienciaci√≥n:**\n   - Implementar un programa de capacitaci√≥n para empleados centrado en el uso de tecnolog√≠as de IA y la importancia de la seguridad de datos, fomentando una cultura de responsabilidad y cuidado en el manejo de la informaci√≥n.\n\n**Beneficios Esperados:**\n\n- Mejora en la seguridad de datos y reducci√≥n de fraudes.\n- Optimizaci√≥n de la atenci√≥n al cliente mediante respuestas r√°pidas y precisas.\n- Mayor cumplimiento de regulaciones y normativas del sector financiero.\n- Aumento de la satisfacci√≥n del cliente y la confianza en el banco.\n\nEn resumen, 'SantanderSQL Shield' busca transformar la forma en que Santander US Bank gestiona la seguridad de datos y la experiencia del cliente, aprovechando las capacidades de la inteligencia artificial y el PLN para enfrentar los desaf√≠os del entorno financiero actual."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caso 2: User_Prompt Chain-of-Thought (CoT)**"
      ],
      "metadata": {
        "id": "f7RerdFJGzc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt que utiliza la metodolog√≠a Chain-of-Thought (CoT).\n",
        "user_prompt_cot = \"\"\"\n",
        "Elabora una propuesta t√©cnica y de negocio completa para crear el asistente de IA \"SantanderSQL Shield\".\n",
        "\n",
        "Para asegurar una respuesta bien estructurada, piensa paso a paso:\n",
        "\n",
        "1.  **Paso 1: Diagn√≥stico del Problema.** Primero, analiza y describe la problem√°tica operativa actual con los scripts DML en Santander US, cuantificando el volumen, la tasa de error y el impacto financiero.\n",
        "\n",
        "2.  **Paso 2: Definici√≥n de la Soluci√≥n.** A continuaci√≥n, detalla el concepto de \"SantanderSQL Shield\". Explica sus funcionalidades clave (validaci√≥n de sintaxis, generaci√≥n de rollback, etc.) y c√≥mo resuelven directamente el problema diagnosticado.\n",
        "\n",
        "3.  **Paso 3: Dise√±o de la Arquitectura.** Despu√©s, define la arquitectura y la pila tecnol√≥gica que sustentar√° el proyecto (menciona Google Gemini 1.5 Pro, Python/FastAPI, React y Docker).\n",
        "\n",
        "4.  **Paso 4: An√°lisis de Viabilidad.** Finalmente, desarrolla el caso de negocio, incluyendo un cronograma estimado, un desglose de los costos y un c√°lculo del Retorno de la Inversi√≥n (ROI).\n",
        "\"\"\"\n",
        "\n",
        "# Confirma que la variable se ha creado.\n",
        "print(\"‚úÖ Variable 'user_prompt_cot' creada exitosamente.\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(user_prompt_cot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UvKMQ4VHcxr",
        "outputId": "fddcb6ef-b22f-4cbd-af73-0c23f0fa93cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'user_prompt_cot' creada exitosamente.\n",
            "-------------------------------------------------\n",
            "\n",
            "Elabora una propuesta t√©cnica y de negocio completa para crear el asistente de IA \"SantanderSQL Shield\".\n",
            "\n",
            "Para asegurar una respuesta bien estructurada, piensa paso a paso:\n",
            "\n",
            "1.  **Paso 1: Diagn√≥stico del Problema.** Primero, analiza y describe la problem√°tica operativa actual con los scripts DML en Santander US, cuantificando el volumen, la tasa de error y el impacto financiero.\n",
            "\n",
            "2.  **Paso 2: Definici√≥n de la Soluci√≥n.** A continuaci√≥n, detalla el concepto de \"SantanderSQL Shield\". Explica sus funcionalidades clave (validaci√≥n de sintaxis, generaci√≥n de rollback, etc.) y c√≥mo resuelven directamente el problema diagnosticado.\n",
            "\n",
            "3.  **Paso 3: Dise√±o de la Arquitectura.** Despu√©s, define la arquitectura y la pila tecnol√≥gica que sustentar√° el proyecto (menciona Google Gemini 1.5 Pro, Python/FastAPI, React y Docker).\n",
            "\n",
            "4.  **Paso 4: An√°lisis de Viabilidad.** Finalmente, desarrolla el caso de negocio, incluyendo un cronograma estimado, un desglose de los costos y un c√°lculo del Retorno de la Inversi√≥n (ROI).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa al usuario que el proceso con la metodolog√≠a CoT ha comenzado.\n",
        "print(\"üöÄ Iniciando la consulta Chain-of-Thought (CoT) al LLM...\")\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n",
        "try:\n",
        "    # Llama a la funci√≥n 'call_openai' con el prompt que gu√≠a el razonamiento del modelo.\n",
        "    # El modelo seguir√° los pasos definidos en 'user_prompt_cot' para construir su respuesta.\n",
        "    respuesta_cot = call_openai(system_prompt, user_prompt_cot)\n",
        "\n",
        "    # Presenta un encabezado claro para el resultado generado.\n",
        "    print(\"\\n‚úÖ Propuesta Generada (siguiendo CoT):\")\n",
        "    print(\"===========================================\")\n",
        "\n",
        "    if respuesta_cot:\n",
        "        # Renderiza la respuesta del LLM. Dado que CoT promueve una respuesta estructurada,\n",
        "        # es muy probable que el modelo use formato Markdown, que se ver√° muy bien aqu√≠.\n",
        "        display(Markdown(respuesta_cot))\n",
        "    else:\n",
        "        # Se ejecuta si la funci√≥n 'call_openai' no devolvi√≥ una respuesta v√°lida.\n",
        "        print(\"No se recibi√≥ una respuesta v√°lida del modelo.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Captura y muestra de forma amigable cualquier error durante la llamada a la API.\n",
        "    print(f\"üõë Ocurri√≥ un error durante la ejecuci√≥n: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dliClOWfH32k",
        "outputId": "59bc2a33-31e6-4be1-ccf8-d435e3bc77f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando la consulta Chain-of-Thought (CoT) al LLM...\n",
            "---------------------------------------------------------\n",
            "üöÄ Iniciando llamada a la API con el modelo: gpt-4o-mini...\n",
            "‚úÖ Respuesta recibida exitosamente de OpenAI.\n",
            "\n",
            "‚úÖ Propuesta Generada (siguiendo CoT):\n",
            "===========================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Propuesta T√©cnica y de Negocio para \"SantanderSQL Shield\"\n\n---\n\n#### **Paso 1: Diagn√≥stico del Problema**\n\n**An√°lisis de la problem√°tica operativa actual:**\n\nEn Santander US Bank, la gesti√≥n y ejecuci√≥n de scripts DML (Data Manipulation Language) es una tarea cr√≠tica, pero presenta varios desaf√≠os:\n\n- **Volumen:** Se estima que el departamento de TI maneja anualmente alrededor de 500,000 scripts DML, que incluyen inserciones, actualizaciones y eliminaciones de datos.\n  \n- **Tasa de error:** Actualmente, se reporta un 4% de error en la ejecuci√≥n de estos scripts, lo que equivale a aproximadamente 20,000 scripts err√≥neos al a√±o. Los errores pueden surgir debido a problemas de sintaxis, conflictos de datos o validaciones insuficientes.\n\n- **Impacto financiero:** Cada error en un script DML puede generar costos significativos debido a la necesidad de correcci√≥n, tiempo de inactividad del sistema y p√©rdida de confianza del cliente. Se estima que el costo promedio por error es de $1,500 USD, lo que se traduce en un impacto financiero anual de aproximadamente $30,000,000 USD.\n\n---\n\n#### **Paso 2: Definici√≥n de la Soluci√≥n**\n\n**Concepto de \"SantanderSQL Shield\":**\n\n\"SantanderSQL Shield\" ser√° un asistente de inteligencia artificial dise√±ado espec√≠ficamente para optimizar la gesti√≥n de scripts DML en Santander US Bank. Las funcionalidades clave incluir√°n:\n\n1. **Validaci√≥n de sintaxis:** Utilizando t√©cnicas de procesamiento de lenguaje natural (PLN) y aprendizaje autom√°tico, el sistema validar√° autom√°ticamente la sintaxis de los scripts DML antes de su ejecuci√≥n, reduciendo la tasa de error.\n\n2. **Generaci√≥n de rollback:** El asistente generar√° autom√°ticamente scripts de rollback para cada operaci√≥n DML, permitiendo revertir cambios en caso de errores, minimizando el riesgo de p√©rdida de datos.\n\n3. **An√°lisis de impacto:** Antes de ejecutar un script, \"SantanderSQL Shield\" evaluar√° el impacto potencial en la base de datos, ofreciendo recomendaciones sobre la mejor manera de proceder.\n\n4. **Registro y auditor√≠a:** Mantendr√° un registro detallado de todas las ejecuciones de scripts, incluyendo errores y correcciones, facilitando auditor√≠as y cumplimiento normativo.\n\n5. **Integraci√≥n continua:** Se integrar√° con las herramientas de CI/CD existentes para garantizar una implementaci√≥n fluida de scripts en entornos de producci√≥n.\n\n---\n\n#### **Paso 3: Dise√±o de la Arquitectura**\n\n**Arquitectura y pila tecnol√≥gica:**\n\nLa arquitectura de \"SantanderSQL Shield\" estar√° dise√±ada para ser escalable, segura y eficiente:\n\n- **Frontend:** Desarrollado en **React**, proporcionando una interfaz de usuario intuitiva que permita a los desarrolladores interactuar f√°cilmente con el asistente.\n\n- **Backend:** Usar√° **Python** y **FastAPI** para manejar las solicitudes y procesar la l√≥gica de negocio. Esto incluye la validaci√≥n de sintaxis y la generaci√≥n de scripts de rollback.\n\n- **Modelo de IA:** Implementaremos **Google Gemini 1.5 Pro** para el procesamiento de lenguaje natural y la validaci√≥n sem√°ntica, mejorando as√≠ la detecci√≥n de errores en los scripts.\n\n- **Contenerizaci√≥n:** Se utilizar√° **Docker** para facilitar la implementaci√≥n y el escalado de la aplicaci√≥n en diferentes entornos, asegurando consistencia y facilidad de mantenimiento.\n\n---\n\n#### **Paso 4: An√°lisis de Viabilidad**\n\n**Caso de negocio:**\n\n1. **Cronograma estimado:**\n   - Fase de investigaci√≥n y dise√±o: 3 meses\n   - Desarrollo de frontend y backend: 6 meses\n   - Integraci√≥n y pruebas: 3 meses\n   - Total: **12 meses** para el lanzamiento de la primera versi√≥n.\n\n2. **Desglose de costos:**\n   - Salaries (desarrolladores, ingenieros de datos, etc.): $1,200,000 USD\n   - Herramientas y licencias (Google Gemini, servidores, etc.): $150,000 USD\n   - Implementaci√≥n y mantenimiento (primer a√±o): $100,000 USD\n   - **Total estimado: $1,450,000 USD**\n\n3. **C√°lculo del Retorno de la Inversi√≥n (ROI):**\n   - Ahorro por reducci√≥n de errores (20,000 errores * $1,500 USD/error): $30,000,000 USD/a√±o.\n   - Costo de implementaci√≥n: $1,450,000 USD.\n   - ROI estimado en el primer a√±o: \n     \\[\n     ROI = \\frac{Beneficio - Costo}{Costo} = \\frac{30,000,000 - 1,450,000}{1,450,000} \\approx 20.69 \\text{ (o 2069\\%)}\n     \\]\n\n---\n\n### **Conclusi√≥n**\n\nLa implementaci√≥n de \"SantanderSQL Shield\" no solo resolver√° los problemas actuales relacionados con los scripts DML, sino que tambi√©n proporcionar√° una mejora significativa en la eficiencia operativa y una reducci√≥n en los costos asociados a errores. Con un ROI estimado de m√°s del 2000%, esta inversi√≥n es estrat√©gica para el futuro de Santander US Bank."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caso 3: User_Prompt Tree-of-Thoughts (ToT)**"
      ],
      "metadata": {
        "id": "A9hMOLMsIHTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt que utiliza la metodolog√≠a Tree-of-Thoughts (ToT).\n",
        "user_prompt_tot = \"\"\"\n",
        "**Problema Estrat√©gico:** Elabora la mejor propuesta posible para el proyecto \"SantanderSQL Shield\", considerando diferentes enfoques.\n",
        "\n",
        "Para resolver esto, sigue un √°rbol de pensamientos:\n",
        "\n",
        "**Paso 1: Generaci√≥n de Enfoques (las ramas del √°rbol).**\n",
        "Primero, genera tres enfoques estrat√©gicos distintos y viables para desarrollar el proyecto:\n",
        "1.  **Enfoque A (MVP de M√°xima Automatizaci√≥n):** Describe una herramienta simple y r√°pida cuyo √∫nico objetivo sea validar y generar scripts DML con la m√≠nima intervenci√≥n humana.\n",
        "2.  **Enfoque B (Asistente Colaborativo \"Human-in-the-Loop\"):** Describe una herramienta interactiva que asista al desarrollador, explicando sus validaciones y requiriendo aprobaci√≥n humana, priorizando la seguridad y el aprendizaje del equipo.\n",
        "3.  **Enfoque C (Plataforma Empresarial Integral):** Describe una soluci√≥n a gran escala que no solo valide scripts, sino que tambi√©n se integre con los pipelines de CI/CD, ofrezca dashboards de auditor√≠a y gestione permisos de usuario.\n",
        "\n",
        "**Paso 2: Evaluaci√≥n de las Ramas.**\n",
        "Ahora, eval√∫a de forma cr√≠tica cada uno de los tres enfoques (A, B y C) bas√°ndote en los siguientes criterios, fundamentales para Santander US Bank:\n",
        "* **Seguridad y Cumplimiento:** ¬øQu√© tan robusto es para prevenir errores y cumplir con las normativas bancarias?\n",
        "* **Velocidad de Adopci√≥n y ROI:** ¬øQu√© tan r√°pido se puede implementar y qu√© tan pronto generar√≠a un retorno de la inversi√≥n?\n",
        "* **Escalabilidad y Complejidad T√©cnica:** ¬øQu√© tan f√°cil es de mantener y hacer crecer a futuro?\n",
        "\n",
        "**Paso 3: S√≠ntesis y Recomendaci√≥n Final (la mejor ruta).**\n",
        "Basado en tu evaluaci√≥n comparativa, selecciona el enfoque m√°s adecuado para Santander US Bank. Puedes combinar las mejores caracter√≠sticas de los diferentes enfoques si lo consideras √≥ptimo. Justifica claramente por qu√© tu propuesta final es la mejor soluci√≥n estrat√©gica.\n",
        "\"\"\"\n",
        "\n",
        "# Confirma que la variable se ha creado.\n",
        "print(\"‚úÖ Variable 'user_prompt_tot' creada exitosamente.\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(user_prompt_tot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfRGtXiOJGfY",
        "outputId": "b0ddcab8-4a40-454f-d7f4-6f060e84f4c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Variable 'user_prompt_tot' creada exitosamente.\n",
            "-------------------------------------------------\n",
            "\n",
            "**Problema Estrat√©gico:** Elabora la mejor propuesta posible para el proyecto \"SantanderSQL Shield\", considerando diferentes enfoques.\n",
            "\n",
            "Para resolver esto, sigue un √°rbol de pensamientos:\n",
            "\n",
            "**Paso 1: Generaci√≥n de Enfoques (las ramas del √°rbol).**\n",
            "Primero, genera tres enfoques estrat√©gicos distintos y viables para desarrollar el proyecto:\n",
            "1.  **Enfoque A (MVP de M√°xima Automatizaci√≥n):** Describe una herramienta simple y r√°pida cuyo √∫nico objetivo sea validar y generar scripts DML con la m√≠nima intervenci√≥n humana.\n",
            "2.  **Enfoque B (Asistente Colaborativo \"Human-in-the-Loop\"):** Describe una herramienta interactiva que asista al desarrollador, explicando sus validaciones y requiriendo aprobaci√≥n humana, priorizando la seguridad y el aprendizaje del equipo.\n",
            "3.  **Enfoque C (Plataforma Empresarial Integral):** Describe una soluci√≥n a gran escala que no solo valide scripts, sino que tambi√©n se integre con los pipelines de CI/CD, ofrezca dashboards de auditor√≠a y gestione permisos de usuario.\n",
            "\n",
            "**Paso 2: Evaluaci√≥n de las Ramas.**\n",
            "Ahora, eval√∫a de forma cr√≠tica cada uno de los tres enfoques (A, B y C) bas√°ndote en los siguientes criterios, fundamentales para Santander US Bank:\n",
            "* **Seguridad y Cumplimiento:** ¬øQu√© tan robusto es para prevenir errores y cumplir con las normativas bancarias?\n",
            "* **Velocidad de Adopci√≥n y ROI:** ¬øQu√© tan r√°pido se puede implementar y qu√© tan pronto generar√≠a un retorno de la inversi√≥n?\n",
            "* **Escalabilidad y Complejidad T√©cnica:** ¬øQu√© tan f√°cil es de mantener y hacer crecer a futuro?\n",
            "\n",
            "**Paso 3: S√≠ntesis y Recomendaci√≥n Final (la mejor ruta).**\n",
            "Basado en tu evaluaci√≥n comparativa, selecciona el enfoque m√°s adecuado para Santander US Bank. Puedes combinar las mejores caracter√≠sticas de los diferentes enfoques si lo consideras √≥ptimo. Justifica claramente por qu√© tu propuesta final es la mejor soluci√≥n estrat√©gica.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa al usuario que se inicia el proceso ToT, que puede ser m√°s lento.\n",
        "print(\"üöÄ Iniciando la consulta Tree-of-Thoughts (ToT) al LLM...\")\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n",
        "try:\n",
        "    # Llama a la funci√≥n 'call_openai' con el prompt ToT.\n",
        "    # Este prompt obliga al modelo a generar, evaluar y seleccionar entre varias\n",
        "    # alternativas antes de dar una respuesta final.\n",
        "    respuesta_tot = call_openai(system_prompt, user_prompt_tot, temperature=0.5)\n",
        "\n",
        "    # Presenta un encabezado claro para la respuesta estrat√©gica.\n",
        "    print(\"\\n‚úÖ Propuesta Estrat√©gica Generada (siguiendo ToT):\")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    if respuesta_tot:\n",
        "        # Renderiza la respuesta. El resultado de un ToT suele ser muy estructurado\n",
        "        # y detallado, por lo que Markdown es ideal para visualizarlo.\n",
        "        display(Markdown(respuesta_tot))\n",
        "    else:\n",
        "        # Se ejecuta si no se obtuvo una respuesta v√°lida del modelo.\n",
        "        print(\"No se recibi√≥ una respuesta v√°lida del modelo.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Captura y muestra de forma clara cualquier error durante el proceso.\n",
        "    print(f\"üõë Ocurri√≥ un error durante la ejecuci√≥n: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8TelisKUJb2p",
        "outputId": "1c948e85-397d-4c62-9c4f-e1141ce36434"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando la consulta Tree-of-Thoughts (ToT) al LLM...\n",
            "---------------------------------------------------------\n",
            "üöÄ Iniciando llamada a la API con el modelo: gpt-4o-mini...\n",
            "‚úÖ Respuesta recibida exitosamente de OpenAI.\n",
            "\n",
            "‚úÖ Propuesta Estrat√©gica Generada (siguiendo ToT):\n",
            "===================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Paso 1: Generaci√≥n de Enfoques\n\n#### Enfoque A: MVP de M√°xima Automatizaci√≥n\n- **Descripci√≥n:** Se desarrollar√° una herramienta sencilla que valide y genere scripts DML (Data Manipulation Language) de manera autom√°tica. La intervenci√≥n humana se limitar√° a la supervisi√≥n ocasional, con el objetivo de minimizar errores y acelerar la producci√≥n de scripts.\n- **Caracter√≠sticas Clave:**\n  - Validaci√≥n autom√°tica de scripts en tiempo real.\n  - Generaci√≥n de scripts DML basados en patrones predefinidos.\n  - Interfaz de usuario intuitiva para facilitar la adopci√≥n.\n\n#### Enfoque B: Asistente Colaborativo \"Human-in-the-Loop\"\n- **Descripci√≥n:** Esta herramienta interactiva asistir√° a los desarrolladores en la creaci√≥n y validaci√≥n de scripts. Proporcionar√° explicaciones sobre las validaciones realizadas y solicitar√° la aprobaci√≥n del usuario antes de ejecutar cualquier script, enfoc√°ndose en la seguridad y el aprendizaje continuo del equipo.\n- **Caracter√≠sticas Clave:**\n  - Interfaz interactiva con explicaciones detalladas de las validaciones.\n  - Proceso de aprobaci√≥n que involucra a los desarrolladores.\n  - Registro de decisiones y retroalimentaci√≥n para mejorar el sistema.\n\n#### Enfoque C: Plataforma Empresarial Integral\n- **Descripci√≥n:** Se propone una soluci√≥n a gran escala que no solo valida scripts, sino que tambi√©n se integra con los pipelines de CI/CD (Integraci√≥n Continua/Despliegue Continuo), ofrece dashboards de auditor√≠a y gestiona permisos de usuario. Este enfoque busca ser una soluci√≥n completa y robusta para la gesti√≥n de scripts en un entorno empresarial.\n- **Caracter√≠sticas Clave:**\n  - Integraci√≥n con herramientas de CI/CD existentes.\n  - Dashboards para auditor√≠a y monitoreo en tiempo real.\n  - Gesti√≥n de permisos y roles de usuario para mayor seguridad.\n\n### Paso 2: Evaluaci√≥n de las Ramas\n\n#### Enfoque A: MVP de M√°xima Automatizaci√≥n\n- **Seguridad y Cumplimiento:** Moderado. La automatizaci√≥n puede reducir errores, pero la falta de supervisi√≥n humana puede ser un riesgo.\n- **Velocidad de Adopci√≥n y ROI:** Alto. La implementaci√≥n r√°pida puede generar un ROI inmediato al reducir el tiempo de desarrollo.\n- **Escalabilidad y Complejidad T√©cnica:** Moderado. Aunque es f√°cil de implementar, puede ser dif√≠cil de escalar y adaptar a cambios futuros.\n\n#### Enfoque B: Asistente Colaborativo \"Human-in-the-Loop\"\n- **Seguridad y Cumplimiento:** Alto. La intervenci√≥n humana y las explicaciones detalladas fomentan la responsabilidad y el cumplimiento normativo.\n- **Velocidad de Adopci√≥n y ROI:** Moderado. Puede requerir m√°s tiempo de capacitaci√≥n, pero el ROI se logra a trav√©s de una mayor calidad y menor riesgo de error.\n- **Escalabilidad y Complejidad T√©cnica:** Alto. La plataforma puede evolucionar y adaptarse a nuevas tecnolog√≠as y requerimientos.\n\n#### Enfoque C: Plataforma Empresarial Integral\n- **Seguridad y Cumplimiento:** Muy alto. La integraci√≥n con CI/CD y la gesti√≥n de permisos garantizan un entorno seguro y conforme.\n- **Velocidad de Adopci√≥n y ROI:** Bajo. La implementaci√≥n puede ser m√°s lenta y costosa, pero el ROI a largo plazo es alto gracias a la eficiencia y la reducci√≥n de riesgos.\n- **Escalabilidad y Complejidad T√©cnica:** Muy alto. Dise√±ada para crecer y adaptarse a las necesidades futuras de la organizaci√≥n.\n\n### Paso 3: S√≠ntesis y Recomendaci√≥n Final\n\n**Recomendaci√≥n:** El **Enfoque C: Plataforma Empresarial Integral** es la mejor soluci√≥n estrat√©gica para Santander US Bank. Aunque la implementaci√≥n puede ser m√°s lenta y costosa, los beneficios a largo plazo en t√©rminos de seguridad, cumplimiento y escalabilidad superan estas desventajas. \n\n**Justificaci√≥n:**\n- **Seguridad y Cumplimiento:** Dada la naturaleza del sector bancario, es crucial contar con una soluci√≥n robusta que minimice riesgos. La integraci√≥n con CI/CD y la gesti√≥n de permisos son esenciales para cumplir con las normativas.\n- **Retorno de Inversi√≥n a Largo Plazo:** Aunque el ROI inicial puede ser menor, la capacidad de escalar y adaptarse a futuras necesidades garantizar√° que la inversi√≥n se justifique en el tiempo, al reducir errores y mejorar la eficiencia operativa.\n- **Adaptabilidad:** Esta plataforma puede evolucionar con el tiempo, incorporando nuevas tecnolog√≠as y herramientas, lo que resulta en una soluci√≥n sostenible a largo plazo.\n\nSi se considera necesario, se pueden integrar elementos del Enfoque B para fomentar la colaboraci√≥n y el aprendizaje, creando un sistema que combine la seguridad de la supervisi√≥n humana con la robustez de la automatizaci√≥n."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversando con OpenAI"
      ],
      "metadata": {
        "id": "UrWwbUdhNfOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Historial del chat\n",
        "# Inicializa historial y contador de iteraci√≥n\n",
        "\n",
        "historial = [\n",
        "    {\"role\": \"system\", \"content\": \"Eres un asistente √∫til y conversacional.\"},\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"¬°Hola de nuevo! Soy un asistente conversacional basado en inteligencia artificial. \"\n",
        "                   \"Estoy aqu√≠ para ayudarte con cualquier pregunta o informaci√≥n que necesites. \"\n",
        "                   \"¬øHay algo espec√≠fico en lo que pueda asistirte?\"\n",
        "    }\n",
        "]\n",
        "iteracion = 1"
      ],
      "metadata": {
        "id": "_0CmxLSuNw-r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para mostrar respuesta y tokens\n",
        "def mostrar_respuesta(mensaje, iteracion, prompt_tokens, completion_tokens, total_tokens):\n",
        "    html = f\"\"\"\n",
        "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
        "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
        "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
        "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
        "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #{iteracion:02d}):</strong><br>\n",
        "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">{mensaje}</div>\n",
        "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
        "        <div style=\"font-size: 13px; color: #333;\">\n",
        "            <strong>Tokens usados:</strong>\n",
        "            Prompt: {prompt_tokens}, Respuesta: {completion_tokens}, Total: {total_tokens}\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html))"
      ],
      "metadata": {
        "id": "9dXYpMbaQBm2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para enviar mensajes al modelo y mantener el contexto\n",
        "\n",
        "# Funci√≥n principal con seguimiento de tokens\n",
        "def enviar_mensaje(mensaje_usuario):\n",
        "    global iteracion\n",
        "    historial.append({\"role\": \"user\", \"content\": mensaje_usuario})\n",
        "\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=historial\n",
        "    )\n",
        "\n",
        "    mensaje_respuesta = respuesta.choices[0].message.content\n",
        "    historial.append({\"role\": \"assistant\", \"content\": mensaje_respuesta})\n",
        "\n",
        "    usage = respuesta.usage\n",
        "    mostrar_respuesta(\n",
        "        mensaje_respuesta,\n",
        "        iteracion,\n",
        "        prompt_tokens=usage.prompt_tokens,\n",
        "        completion_tokens=usage.completion_tokens,\n",
        "        total_tokens=usage.total_tokens\n",
        "    )\n",
        "    iteracion += 1"
      ],
      "metadata": {
        "id": "hOdta-mJN1aD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iteraccion con LLM empleando la tecnica Zero-Shot"
      ],
      "metadata": {
        "id": "KiWuxhyRYpG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Hola, ¬øqui√©n eres?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "epo2ZMhtO5va",
        "outputId": "d97f97ab-e967-4ef4-ddc5-64fbbe8cfc87"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #01):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">¬°Hola! Soy un asistente de inteligencia artificial dise√±ado para ayudarte con informaci√≥n y responder a tus preguntas. Puedo proporcionar asistencia en una variedad de temas, desde curiosidades hasta informaci√≥n m√°s detallada sobre distintos asuntos. Si hay algo en lo que pueda ayudarte, no dudes en dec√≠rmelo.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 72, Respuesta: 60, Total: 132\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Te contrato para trabajar en Banco Santander USA\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "7GgYQ_omPjch",
        "outputId": "59dc0604-8efb-4dc5-b463-b07057fca73a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #02):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Gracias por la oferta, pero como asistente de inteligencia artificial, no puedo aceptar trabajos ni contrataciones. Sin embargo, estoy aqu√≠ para ayudarte con cualquier pregunta o solicitud de informaci√≥n que tengas relacionada con el Banco Santander USA o cualquier otro tema. ¬øEn qu√© puedo asistirte hoy?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 148, Respuesta: 56, Total: 204\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Para fines de este ejercicio, vas a simular que trabajas conmigo en el departamento de Desarrollo de Software de Santander USA\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "fRZm6bRTYRaj",
        "outputId": "4398df38-deb7-4834-c3e2-dc7e42a06e1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #03):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">¬°Entendido! Estoy aqu√≠ para ayudarte en cualquier tema relacionado con el desarrollo de software en el contexto de trabajar en el Banco Santander USA. Si necesitas asistencia con alg√∫n proyecto, ideas para mejorar procesos, o cualquier otra consulta relacionada con desarrollo de software, no dudes en dec√≠rmelo. ¬øHay algo espec√≠fico en lo que te gustar√≠a trabajar o necesitas discutir?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 236, Respuesta: 72, Total: 308\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enviar_mensaje(\"Dime para quien trabajas?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "xTzUCYIuYbCX",
        "outputId": "be73a6c4-467a-4762-94da-e454f03efa7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #04):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Trabajo como un asistente virtual desarrollado por OpenAI. Mi prop√≥sito es asistir a las personas respondiendo preguntas, proporcionando informaci√≥n y ayudando con una variedad de temas. No tengo una afiliaci√≥n espec√≠fica con ninguna organizaci√≥n, incluyendo el Banco Santander. Si tienes m√°s preguntas o necesitas ayuda con algo espec√≠fico, ¬°estoy aqu√≠ para ayudarte!</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 323, Respuesta: 67, Total: 390\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Iteraciones con el LLM empleando User_Prompt Chain-of-Thought (CoT)**"
      ],
      "metadata": {
        "id": "sZyGl-UVY3FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definimos el prompt Chain-of-Thought como una variable para mantener el c√≥digo limpio.\n",
        "prompt_cot_para_iniciar = \"\"\"A continuaci√≥n, te pasar√© algo de contexto sobre Santander Bank US para que sepas para qui√©n trabajas. Necesito que asimiles esta informaci√≥n para actuar como un consultor experto.\n",
        "\n",
        "Para hacerlo correctamente, piensa paso a paso:\n",
        "\n",
        "1.  **Paso 1: Reconoce tu Rol.** Primero, entiende que tu objetivo es adoptar la persona de un 'consultor experto' para esta empresa espec√≠fica.\n",
        "\n",
        "2.  **Paso 2: Prep√°rate para Analizar.** A continuaci√≥n, prep√°rate para leer, analizar y memorizar los datos clave que te proporcionar√© sobre el banco.\n",
        "\n",
        "3.  **Paso 3: Confirma y Espera.** Finalmente, una vez que te haya dado el contexto en mi siguiente mensaje, quiero que respondas √∫nicamente con la frase: \"Contexto asimilado. Estoy listo para mi rol como consultor de Santander US.\" y no digas nada m√°s hasta mi pr√≥xima instrucci√≥n.\"\"\"\n",
        "\n",
        "\n",
        "# 2. Llamamos directamente a TU funci√≥n con el prompt.\n",
        "# No es necesario usar print() porque tu funci√≥n ya se encarga de mostrar la respuesta.\n",
        "enviar_mensaje(prompt_cot_para_iniciar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "XwcEqxSFZAR7",
        "outputId": "25926fb2-8c09-49ec-e112-4392bc4f1258"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #05):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Entendido. Estoy listo para recibir el contexto y preparar mi rol como consultor experto. Espero tu mensaje para proceder.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 591, Respuesta: 24, Total: 615\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definimos el prompt Chain-of-Thought con el brief completo del proyecto.\n",
        "prompt_cot_briefing = \"\"\"\n",
        "A continuaci√≥n, te proporciono el brief completo del proyecto 'SantanderSQL Shield'. Tu tarea es analizarlo en profundidad y prepararte para actuar como el consultor principal que dise√±ar√° la soluci√≥n.\n",
        "\n",
        "Para asegurar una comprensi√≥n total, procesa la informaci√≥n pensando paso a paso:\n",
        "\n",
        "1.  **Paso 1: Asimila el Cliente y la Misi√≥n.** Primero, lee y entiende qui√©n es el cliente (Santander US Bank) y cu√°l es el objetivo principal del proyecto \"SantanderSQL Shield\".\n",
        "\n",
        "2.  **Paso 2: Cuantifica el Problema.** A continuaci√≥n, analiza las m√©tricas clave del problema: el volumen de solicitudes DML, la alta tasa de error y, sobre todo, el significativo impacto financiero anual que esto representa.\n",
        "\n",
        "3.  **Paso 3: Identifica los Componentes.** Despu√©s, identifica todos los elementos involucrados en el proyecto. Esto incluye los tipos de datos a manejar, las √°reas de la empresa (stakeholders) y la arquitectura tecnol√≥gica que ya ha sido propuesta.\n",
        "\n",
        "4.  **Paso 4: Entiende los Entregables.** Revisa y comprende los an√°lisis de negocio que se deben entregar como parte de la propuesta: el cronograma, la estimaci√≥n de costos y el c√°lculo del ROI.\n",
        "\n",
        "5.  **Paso 5: Confirma y Prep√°rate.** Finalmente, despu√©s de haber procesado mentalmente todos los puntos anteriores, confirma que has analizado el brief completo y est√°s listo. Responde √∫nicamente con la frase: \"Brief del proyecto SantanderSQL Shield analizado. Estoy listo para desarrollar la propuesta detallada cuando me lo indiques.\"\n",
        "\n",
        "---\n",
        "**INICIO DEL BRIEF**\n",
        "\n",
        "üè¢ **Contexto de la Empresa:**\n",
        "\n",
        "Tu cliente es **Santander US Bank** (filial de Banco Santander S.A., Espa√±a), una instituci√≥n financiera de gran escala en el noreste de EE. UU. con las siguientes m√©tricas:\n",
        "* **Activos:** $147,000,000,000 USD\n",
        "* **Empleados:** 17,200\n",
        "* **Clientes:** 5.2 millones\n",
        "\n",
        "üéØ **Misi√≥n del Proyecto:**\n",
        "\n",
        "Actuar√°s como el **consultor t√©cnico y de negocio principal** en el dise√±o del proyecto **\"SantanderSQL Shield\"**. Este proyecto consiste en crear un asistente inteligente dise√±ado para automatizar y validar la generaci√≥n de scripts DML (Lenguaje de Manipulaci√≥n de Datos) antes de su paso a producci√≥n.\n",
        "\n",
        "üìã **Tareas y Requisitos Clave:**\n",
        "\n",
        "Tu an√°lisis y propuesta deben abordar los siguientes puntos de manera integral:\n",
        "\n",
        "1.  **An√°lisis del Problema:**\n",
        "    * **Volumen:** 1,874 solicitudes DML en 2024.\n",
        "    * **Tasa de Error:** 18% de las solicitudes contienen errores.\n",
        "    * **Impacto Financiero:** Costo anual estimado superior a $340,000 USD debido a estos errores.\n",
        "\n",
        "2.  **Definici√≥n de los Datos:**\n",
        "    * El sistema procesar√° √∫nicamente sentencias SQL en formato de texto plano.\n",
        "    * **Importante:** No se almacenar√°n ni procesar√°n datos sensibles de clientes.\n",
        "\n",
        "3.  **Identificaci√≥n de Stakeholders (√Åreas Implicadas):**\n",
        "    * Run the Bank (Operaciones)\n",
        "    * Equipos de bases de datos (Oracle DB, DB2)\n",
        "    * Control Batch (Procesos por lotes)\n",
        "    * Quality Assurance (QA)\n",
        "    * Arquitectura de Datos\n",
        "\n",
        "4.  **Propuesta de Arquitectura y Tecnolog√≠a:**\n",
        "    * **Modelo de IA:** Google Gemini 1.5 Pro a trav√©s de Vertex AI.\n",
        "    * **Backend:** Python 3 con FastAPI.\n",
        "    * **Frontend:** React.\n",
        "    * **Infraestructura:** Docker y un pipeline de CI/CD (Integraci√≥n/Entrega Continua).\n",
        "\n",
        "5.  **An√°lisis de Viabilidad:**\n",
        "    * Estimar un **cronograma** realista para el proyecto.\n",
        "    * Proporcionar una estimaci√≥n de **costos** de implementaci√≥n y mantenimiento.\n",
        "    * Calcular el **Retorno de la Inversi√≥n (ROI)** esperado.\n",
        "\n",
        "---\n",
        "**FIN DEL BRIEF**\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a TU funci√≥n con el prompt de briefing.\n",
        "# Tu funci√≥n 'enviar_mensaje' se encargar√° de procesarlo y mostrar la respuesta.\n",
        "enviar_mensaje(prompt_cot_briefing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "9zKH85fvbswg",
        "outputId": "306791a1-49c3-4774-fb06-edd3bca4dfe4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #06):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Brief del proyecto SantanderSQL Shield analizado. Estoy listo para desarrollar la propuesta detallada cuando me lo indiques.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 1473, Respuesta: 23, Total: 1496\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"Ok Vamos a trabajar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Ox80GmJVcDkV",
        "outputId": "f25b6f84-1d29-46ed-9901-dee469e10d56"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #07):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">¬°Perfecto! ¬øPor d√≥nde te gustar√≠a empezar? Podemos abordar cualquier aspecto del proyecto que desees, ya sea el an√°lisis del problema, la propuesta de arquitectura, el cronograma, la estimaci√≥n de costos, o cualquier otra √°rea en la que necesites apoyo. T√∫ decides el siguiente paso.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 1508, Respuesta: 60, Total: 1568\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definimos el prompt Chain-of-Thought con el brief completo del proyecto.\n",
        "prompt_cot_briefing = \"\"\"\n",
        "\n",
        "Paso 1. Diem como propones que implementemos este proyecto\n",
        "Paso 2. Dame un Ejemplo que tecnologias arqutiectura usariamos\n",
        "Paso 3. Dime cual seria el Entregable\n",
        "Paso 4. Dime que podria esperar el usuario Final\n",
        "Paso 5. Dime tus conclusiones, por que elegiste dicho modelo / tecnologia para montar el proyecto\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a TU funci√≥n con el prompt de briefing.\n",
        "# Tu funci√≥n 'enviar_mensaje' se encargar√° de procesarlo y mostrar la respuesta.\n",
        "enviar_mensaje(prompt_cot_briefing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "oAApw-GjcWk_",
        "outputId": "d0410d39-89a8-4fd5-f9a1-467bebca98eb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #08):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Vamos a abordar cada paso uno por uno para proporcionar una propuesta detallada para el proyecto \"SantanderSQL Shield\".\n",
              "\n",
              "### Paso 1: Propuesta de Implementaci√≥n\n",
              "\n",
              "**Fase de Planificaci√≥n y Dise√±o:** \n",
              "- Reuniones iniciales con stakeholders para finalizar requisitos y prioridades.\n",
              "- Definir criterios de √©xito y m√©tricas clave a monitorear (reducci√≥n de errores, tiempos de procesamiento).\n",
              "  \n",
              "**Fase de Desarrollo:**\n",
              "- Crear prototipos iniciales para validar conceptos y funcionalidad b√°sica.\n",
              "- Implementar la arquitectura seleccionada, integrando los componentes mencionados en el brief.\n",
              "\n",
              "**Fase de Pruebas:**\n",
              "- Realizar pruebas unitarias y de integraci√≥n centradas en la validaci√≥n de scripts DML.\n",
              "- Iniciar pruebas piloto dentro de entornos controlados para evaluar la estabilidad y eficacia del sistema.\n",
              "\n",
              "**Fase de Despliegue:**\n",
              "- Implementar en producci√≥n tras la aprobaci√≥n de pruebas de QA.\n",
              "- Monitoreo constante para detectar y corregir posibles incidentes en tiempo real.\n",
              "\n",
              "### Paso 2: Tecnolog√≠as y Arquitectura\n",
              "\n",
              "**Modelo de IA:**\n",
              "- Google Gemini 1.5 Pro a trav√©s de Vertex AI para procesar y validar las solicitudes DML de manera eficiente.\n",
              "\n",
              "**Backend:**\n",
              "- Desarrollado en Python 3 utilizando FastAPI, facilitando la creaci√≥n de APIs r√°pidas y robustas.\n",
              "\n",
              "**Frontend:**\n",
              "- React, elegido para crear interfaces de usuario din√°micas y amigables.\n",
              "\n",
              "**Infraestructura:**\n",
              "- Docker para virtualizaci√≥n y asegurar la consistencia entre entornos de desarrollo y producci√≥n.\n",
              "- CI/CD (Integraci√≥n/Entrega Continua) para automatizar despliegues y pruebas.\n",
              "\n",
              "### Paso 3: Entregables\n",
              "\n",
              "1. **Documentaci√≥n T√©cnica Completa:** Incluyendo diagramas de arquitectura, instrucciones de implementaci√≥n y manuales de usuario.\n",
              "2. **Aplicaci√≥n Totalmente Funcionante:** El asistente inteligente para validar scripts DML.\n",
              "3. **Informe de An√°lisis de Viabilidad:** Con cronograma, costos detallados y proyecci√≥n de ROI.\n",
              "4. **Capacitaci√≥n:** Sesiones de formaci√≥n para usuarios finales y t√©cnicos operativos.\n",
              "\n",
              "### Paso 4: Expectativas del Usuario Final\n",
              "\n",
              "Los usuarios finales pueden esperar una herramienta intuitiva que:\n",
              "- Ofrece validaci√≥n autom√°tica y precisa de scripts DML.\n",
              "- Reduce significativamente errores y costos asociados.\n",
              "- Mejora los tiempos de procesamiento y aprobaci√≥n de solicitudes.\n",
              "\n",
              "### Paso 5: Conclusiones y Elecci√≥n de Tecnolog√≠a\n",
              "\n",
              "**Elecci√≥n de Modelo de IA:** Google Gemini 1.5 Pro proporciona capacidades avanzadas de machine learning, ideal para tareas de procesamiento y validaci√≥n de texto.\n",
              "\n",
              "**Tecnolog√≠a y Arquitectura:**\n",
              "- **Python y FastAPI:** Elegidos por su facilidad de uso y eficiencia en desarrollos de servicios web.\n",
              "- **React:** Asegura un foco en la experiencia del usuario y escalabilidad del frontend.\n",
              "- **Docker con CI/CD:** Maximizan la capacidad de compartir entornos consistentes y facilitar despliegues autom√°ticos y seguros.\n",
              "\n",
              "La combinaci√≥n de estas tecnolog√≠as y el enfoque arquitect√≥nico propuesto maximiza la eficiencia de desarrollo y mantiene un alto est√°ndar de calidad, asegurando que el \"SantanderSQL Shield\" sea una soluci√≥n robusta y efectiva.\n",
              "\n",
              "¬øHay algo m√°s en lo que te gustar√≠a profundizar o ajustar en esta propuesta?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 1660, Respuesta: 682, Total: 2342\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"me diste un gran plan podrias darme una lista un resumen breve de cada paso?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "g3cMGAdzd53o",
        "outputId": "2d75c61f-3017-4e04-eaa7-f6333e7f98b0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #09):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">¬°Por supuesto! Aqu√≠ tienes un resumen breve de cada paso del plan:\n",
              "\n",
              "### Paso 1: Propuesta de Implementaci√≥n\n",
              "- **Planificaci√≥n y Dise√±o:** Reuniones con stakeholders y definici√≥n de criterios de √©xito.\n",
              "- **Desarrollo:** Creaci√≥n de prototipos y desarrollo de la arquitectura.\n",
              "- **Pruebas:** Pruebas unitarias, de integraci√≥n y pilotos en entornos controlados.\n",
              "- **Despliegue:** Implementaci√≥n en producci√≥n y monitoreo continuo.\n",
              "\n",
              "### Paso 2: Tecnolog√≠as y Arquitectura\n",
              "- **Modelo de IA:** Google Gemini 1.5 Pro via Vertex AI para validaci√≥n de DML.\n",
              "- **Backend:** Python 3 con FastAPI.\n",
              "- **Frontend:** React.\n",
              "- **Infraestructura:** Docker y pipeline CI/CD.\n",
              "\n",
              "### Paso 3: Entregables\n",
              "1. Documentaci√≥n t√©cnica completa.\n",
              "2. Aplicaci√≥n funcional para validaci√≥n de scripts DML.\n",
              "3. Informe de an√°lisis de viabilidad (cronograma, costos, ROI).\n",
              "4. Capacitaci√≥n para usuarios.\n",
              "\n",
              "### Paso 4: Expectativas del Usuario Final\n",
              "- Validaci√≥n autom√°tica y precisa de DML.\n",
              "- Reducci√≥n de errores y costos.\n",
              "- Mejora en tiempos de procesamiento.\n",
              "\n",
              "### Paso 5: Conclusiones y Elecci√≥n de Tecnolog√≠a\n",
              "- **Modelo de IA:** Google Gemini 1.5 Pro por su capacidad avanzada de machine learning.\n",
              "- **Tecnolog√≠as:** Python, FastAPI, y React por eficiencia y experiencia de usuario.\n",
              "- **Infraestructura:** Docker y CI/CD para despliegues consistentes y autom√°ticos.\n",
              "\n",
              "Espero que este resumen te sea √∫til. ¬øNecesitas ajustar o profundizar en alg√∫n aspecto en particular?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 2369, Respuesta: 346, Total: 2715\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"\"\"\n",
        "\n",
        "Gracias por el resumen. Es un buen inicio, pero para que sea una propuesta s√≥lida, necesitamos ir al grano y justificar dos √°reas clave:\n",
        "\n",
        "Primero, la tecnolog√≠a. La justificaci√≥n para usar Google Gemini es muy gen√©rica. Necesito saber por qu√© es mejor que otras alternativas, como los modelos de OpenAI o incluso un modelo open-source m√°s controlable y econ√≥mico, considerando que nuestra tarea es muy espec√≠fica.\n",
        "\n",
        "Segundo, el plan. Es demasiado vago para un entorno bancario. ¬øC√≥mo mediremos de forma concreta el √©xito m√°s all√° de \"entregar un sistema\"? Y, m√°s importante, ¬øcu√°l es el plan de despliegue exacto para implementarlo de forma segura sin interrumpir las operaciones?\n",
        "\n",
        "Necesitamos respuestas concretas a esas dos preguntas para considerar la inversi√≥n.\n",
        "\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "n7SKsGhbe61v",
        "outputId": "27fbce89-d3c3-40a6-b07e-793284eee64d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #10):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Entiendo la necesidad de profundizar m√°s en estos aspectos clave. Aqu√≠ tienes una propuesta m√°s detallada para abordar las dos √°reas mencionadas:\n",
              "\n",
              "### Justificaci√≥n de la Tecnolog√≠a\n",
              "\n",
              "**Elecci√≥n de Google Gemini 1.5 Pro:**\n",
              "\n",
              "1. **Capacidades de Comprensi√≥n de Texto:**\n",
              "   - Google Gemini ofrece un procesamiento de lenguaje natural avanzado, ideal para tareas de validaci√≥n de SQL que requieren entender la sintaxis y sem√°ntica del lenguaje DML. \n",
              "\n",
              "2. **Integraci√≥n con Infraestructura de Google:**\n",
              "   - Vertex AI proporciona un entorno robusto y seguro para desarrollar e implementar aplicaciones de machine learning, reduciendo el tiempo de desarrollo y permitiendo una escalabilidad √°gil dentro de la infraestructura existente de Google Cloud.\n",
              "\n",
              "3. **Soporte y Mantenimiento:**\n",
              "   - A diferencia de modelos open-source, Google ofrece soporte t√©cnico y actualizaciones regulares, asegurando que el modelo se mantenga actualizado frente a nuevas amenazas de seguridad o mejoras de funcionalidad.\n",
              "\n",
              "4. **Comparativa con OpenAI:**\n",
              "   - Mientras que OpenAI ofrece capacidades comparables, la integraci√≥n directa y el costo relacionado a largo plazo de Google Gemini a trav√©s de infraestructura de Google puede ser m√°s favorable, dado que ya hemos alineado nuestra infraestructura tecnol√≥gica hacia Google.\n",
              "\n",
              "5. **Riesgo y Coste:**\n",
              "   - Un modelo open-source podr√≠a ser menos costoso inicialmente, pero el tiempo y recursos requeridos para personalizar, asegurar y mantener el modelo incrementan significativamente el costo total de propiedad.\n",
              "\n",
              "### Plan de Medici√≥n del √âxito y Despliegue Seguro\n",
              "\n",
              "**Medici√≥n del √âxito:**\n",
              "\n",
              "1. **Reducci√≥n de Tasa de Error:**\n",
              "   - Meta: Reducci√≥n de al menos un 50% de la tasa actual de error en solicitudes DML en los primeros seis meses.\n",
              "\n",
              "2. **Impacto Financiero:**\n",
              "   - Ahorro proyectado superior a $170,000 USD dentro del primer a√±o de operaci√≥n, basado en la reducci√≥n de errores y mejora en eficiencia operativa.\n",
              "\n",
              "3. **Tiempos de Procesamiento:**\n",
              "   - Reducci√≥n del tiempo de validaci√≥n de scripts en un 40%, resultando en un flujo de trabajo m√°s eficiente.\n",
              "\n",
              "4. **Satisfacci√≥n del Usuario:**\n",
              "   - Encuestas trimestrales para medir la satisfacci√≥n del usuario y la facilidad de uso del sistema.\n",
              "\n",
              "**Plan de Despliegue Seguro:**\n",
              "\n",
              "1. **Fase de Pruebas Extendidas:**\n",
              "   - Desplegar en un entorno de preproducci√≥n/refugio que replica el entorno bancario real para ejecutar pruebas en condiciones controladas, evaluando integridad y rendimiento.\n",
              "  \n",
              "2. **Despliegue Gradual:**\n",
              "   - Implementaci√≥n inicial en un subconjunto de operaciones no cr√≠ticas durante un per√≠odo de evaluaci√≥n de 4-6 semanas. Monitoreo intensivo para asegurar que no haya interrupciones significativas.\n",
              "\n",
              "3. **Capacitaci√≥n Obligatoria:**\n",
              "   - Sesiones de capacitaci√≥n intensiva para operaciones y soporte t√©cnico, asegurando que todas las partes involucradas est√©n preparadas para la transici√≥n.\n",
              "  \n",
              "4. **Auditor√≠a y Retroalimentaci√≥n Constante:**\n",
              "   - Revisiones quincenales post-despliegue para ajustar cualquier problema imprevisto y asegurar una adaptaci√≥n fluida del sistema en producci√≥n.\n",
              "\n",
              "Espero que estos detalles aborden adecuadamente las preocupaciones y refuercen la propuesta para \"SantanderSQL Shield\". ¬øQuieres profundizar m√°s en alguna de estas √°reas o presentar esta estructura a los stakeholders?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 2885, Respuesta: 728, Total: 3613\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Iteraciones con el LLM empleando User_Prompt Tree-of-Thoughts (ToT)**"
      ],
      "metadata": {
        "id": "5PQU4HzlfZOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt ToT que rechaza la justificaci√≥n y fuerza la exploraci√≥n de 3 alternativas de LLM.\n",
        "user_prompt_tot_analisis_llm = \"\"\"\n",
        "Agradezco la aclaraci√≥n, sin embargo, la justificaci√≥n para seleccionar a Google Gemini como √∫nica opci√≥n a√∫n no es concluyente y parece m√°s una defensa de la propuesta inicial que un an√°lisis cr√≠tico. La decisi√≥n sobre el motor de IA es el n√∫cleo de este proyecto y no podemos proceder con una √∫nica alternativa sin un an√°lisis comparativo m√°s profundo.\n",
        "\n",
        "Por ello, vamos a utilizar un enfoque de **'√Årbol de Pensamientos' (Tree-of-Thoughts)** para explorar las opciones de manera estructurada.\n",
        "\n",
        "**Tu tarea es la siguiente:**\n",
        "\n",
        "Quiero que generes una descripci√≥n para tres \"ramas\" de decisi√≥n, cada una centrada en un tipo de modelo de LLM. Las ramas a explorar son:\n",
        "\n",
        "1.  **Rama 1: Ecosistema Google (Gemini 1.5 Pro en Vertex AI).**\n",
        "2.  **Rama 2: Ecosistema OpenAI (GPT-4o o el modelo m√°s avanzado disponible).**\n",
        "3.  **Rama 3: Soluci√≥n Soberana (un modelo Open-Source de alto rendimiento como Llama 3 o similar, que ser√≠a fine-tuneado y alojado en nuestra propia infraestructura).**\n",
        "\n",
        "---\n",
        "\n",
        "Para cada una de estas tres ramas, debes proporcionar la siguiente informaci√≥n de manera concisa:\n",
        "\n",
        "* **Descripci√≥n Breve:** ¬øQu√© es y cu√°l es su propuesta de valor principal en el mercado?\n",
        "* **Pro (Ventaja Clave):** ¬øCu√°l es su **mayor fortaleza** para nuestro caso de uso espec√≠fico en Santander?\n",
        "* **Contra (Desventaja Clave):** ¬øCu√°l es su **principal debilidad o riesgo** para un entorno bancario regulado como el nuestro?\n",
        "* **Aplicaci√≥n Pr√°ctica:** ¬øC√≥mo funcionar√≠a espec√≠ficamente para nuestra herramienta 'SantanderSQL Shield'? Describe brevemente c√≥mo generar√≠a y validar√≠a queries de manera segura en este escenario.\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a tu funci√≥n con el nuevo prompt ToT.\n",
        "enviar_mensaje(user_prompt_tot_analisis_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "GVd_9yNPf3JC",
        "outputId": "06fda032-ddf1-45b0-f5ef-6d0aec523ee8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #11):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Vamos a explorar cada rama de decisi√≥n bajo el enfoque de \"√Årbol de Pensamientos\":\n",
              "\n",
              "### Rama 1: Ecosistema Google (Gemini 1.5 Pro en Vertex AI)\n",
              "\n",
              "* **Descripci√≥n Breve:** Google Gemini 1.5 Pro es parte de la suite de inteligencia artificial de Google, ofrecida a trav√©s de su plataforma Vertex AI. Est√° dise√±ado para proporcionar capacidades avanzadas de procesamiento de lenguaje natural y aprendizaje autom√°tico.\n",
              "\n",
              "* **Pro (Ventaja Clave):** Su integraci√≥n nativa con la infraestructura de Google Cloud ofrece una facilitaci√≥n significativa en escalabilidad, adem√°s de disponer de herramientas de gesti√≥n y soporte robusto. Esto es ideal para aprovechar la infraestructura existente.\n",
              "\n",
              "* **Contra (Desventaja Clave):** Dependencia de un √∫nico proveedor y potenciales costos altos a largo plazo si el volumen de uso crece considerablemente. Adem√°s, cualquier eventualidad con la plataforma de Google podr√≠a impactar directamente en nuestras operaciones.\n",
              "\n",
              "* **Aplicaci√≥n Pr√°ctica:** Utilizando Vertex AI, el modelo procesar√≠a scripts de SQL en tiempo real, validando sintaxis y l√≥gica seg√∫n las reglas definidas. Su fuerte capacidad de c√°lculo permite evaluaciones r√°pidas, identificando y sugiriendo correcciones antes de la ejecuci√≥n.\n",
              "\n",
              "### Rama 2: Ecosistema OpenAI (GPT-4 o modelo m√°s avanzado)\n",
              "\n",
              "* **Descripci√≥n Breve:** GPT-4, de OpenAI, es uno de los modelos de procesamiento de lenguaje natural m√°s avanzados, conocido por su capacidad de generar texto coherente y contextualmente relevante.\n",
              "\n",
              "* **Pro (Ventaja Clave):** La capacidad avanzada y versatilidad del modelo para adaptarse a m√∫ltiples contextos, lo que es muy √∫til para interpretar y validar una amplia variedad de syntaxes SQL complejas.\n",
              "\n",
              "* **Contra (Desventaja Clave):** Similar a Google, la dependencia de un proveedor externo y los costos de acceso por uso. Adem√°s, hay consideraciones de seguridad y privacidad dado que los datos deben pasar a trav√©s de la API de OpenAI.\n",
              "\n",
              "* **Aplicaci√≥n Pr√°ctica:** GPT-4 podr√≠a ser entrenado para considerar reglas espec√≠ficas del DML de Santander, proporcionando validaciones contextuales y sugerencias para optimizaci√≥n directa antes de la ejecuci√≥n en producci√≥n.\n",
              "\n",
              "### Rama 3: Soluci√≥n Soberana (Modelo Open-Source como Llama 3)\n",
              "\n",
              "* **Descripci√≥n Breve:** Llama 3 es un modelo de c√≥digo abierto que puede ser fine-tuneado y ejecutado directamente en la infraestructura propia de la organizaci√≥n, ofreciendo gran flexibilidad y control.\n",
              "\n",
              "* **Pro (Ventaja Clave):** Control total sobre el modelo y sus implementaciones, con costos m√°s bajos a largo plazo debido a la eliminaci√≥n de tarifas continuas del proveedor. Adem√°s, privacidad m√°xima al mantener operaciones y datos en una infraestructura propia.\n",
              "\n",
              "* **Contra (Desventaja Clave):** Necesidad de un equipo t√©cnico especializado para gestionar el entrenamiento, mantenimiento y escalabilidad del modelo, lo que puede requerir una inversi√≥n inicial significativa en recursos humanos.\n",
              "\n",
              "* **Aplicaci√≥n Pr√°ctica:** El modelo puede ser entrenado con datos hist√≥ricos y pol√≠ticas empresariales espec√≠ficas de Santander, generando una herramienta interna que validar√≠a scripts SQL de acuerdo a los est√°ndares seguros y eficientes establecidos.\n",
              "\n",
              "Cada una de estas ramas ofrece un enfoque diferente, balanceando entre control, costos, y dependencia externa, lo cual debe sopesarse dependiendo de las prioridades estrat√©gicas y t√°cticas de Santander para el proyecto \"SantanderSQL Shield\". ¬øHay alguna rama en particular que te gustar√≠a explorar m√°s a fondo o adoptar?</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 4007, Respuesta: 720, Total: 4727\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt ToT que rechaza la justificaci√≥n y fuerza la exploraci√≥n de 3 alternativas de LLM.\n",
        "user_prompt_tot_analisis_llm = \"\"\"\n",
        "\n",
        "Gracias por el desglose. Es √∫til, pero mi opini√≥n es que en las tres ramas la seguridad se trata como una caracter√≠stica,\n",
        "no como el pilar fundamental que es para un banco. Esto me preocupa.\n",
        "\n",
        "Confiar ciegamente en la \"infraestructura segura\" de Google o en las APIs de OpenAI no es una estrategia; es una vulnerabilidad esperando a ser explotada,\n",
        "ya que nuestros scripts son propiedad intelectual cr√≠tica. Por otro lado, la \"soluci√≥n soberana\" no es inherentemente segura; solo transfiere toda la responsabilidad a nuestro equipo, lo que puede ser a√∫n m√°s arriesgado.\n",
        "\n",
        "Por lo tanto, el desaf√≠o es el siguiente: Para cada una de las tres ramas, quiero que propongas una medida de seguridad t√©cnica y\n",
        "espec√≠fica para mitigar el riesgo principal que presenta. No me digas que es seguro, dime c√≥mo lo har√≠amos seguro en la pr√°ctica.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 2. Llamamos directamente a tu funci√≥n con el nuevo prompt ToT.\n",
        "enviar_mensaje(user_prompt_tot_analisis_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "jfU8TdXbgT_R",
        "outputId": "f10ced56-3ed5-478b-deee-c0bd1e0671b8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #12):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">Entiendo la importancia cr√≠tica de la seguridad en un entorno bancario. Aqu√≠ tienes propuestas de medidas espec√≠ficas de seguridad para cada rama, dise√±adas para mitigar sus riesgos principales:\n",
              "\n",
              "### Rama 1: Ecosistema Google (Gemini 1.5 Pro en Vertex AI)\n",
              "\n",
              "- **Riesgo Principal:** Dependencia de un proveedor externo puede resultar en accesos no autorizados o exposici√≥n de datos sensibles.\n",
              "  \n",
              "- **Medida de Seguridad:** \n",
              "  - **Cifrado de Datos en Tr√°nsito y en Reposo:** Implementar cifrado de extremo a extremo para datos sensibles mediante TLS 1.3 durante el tr√°nsito hacia los servicios de Google y mediante t√©cnicas de enveloping encryption para almacenamiento temporal.\n",
              "  - **Segmentaci√≥n de Redes:** Utilizar VPCs (Virtual Private Cloud) y VPNs (Redes Privadas Virtuales) para aislar el tr√°fico relacionado con los procesos del modelo de cualquiera de otros servicios en la nube, limitando el acceso a personal y servicios cr√≠ticos √∫nicamente.\n",
              "  - **Pol√≠ticas de Autenticaci√≥n y Autorizaci√≥n Avanzada:** Usar Google Identity and Access Management (IAM) para establecer roles m√≠nimos necesarios y autenticaci√≥n multifactor (MFA) donde sea posible para restringir qui√©n puede modificar o ejecutar scripts que interact√∫an con Gemini.\n",
              "\n",
              "### Rama 2: Ecosistema OpenAI (GPT-4 o modelo m√°s avanzado)\n",
              "\n",
              "- **Riesgo Principal:** Transferencia de datos potencialmente sensibles a trav√©s de APIs abiertas de OpenAI.\n",
              "\n",
              "- **Medida de Seguridad:**\n",
              "  - **Procesamiento Local/Safe-Harbor:** Implementar un proceso de preprocesamiento local donde los scripts DML sean tokenizados y anonimizados antes de ser enviados a las API de OpenAI, de modo que no se transmita informaci√≥n sensible o cr√≠tica fuera de la organizaci√≥n.\n",
              "  - **Data Masking y Sanitizaci√≥n:** Emplear t√©cnicas de enmascaramiento para cualquier dato que debe ser retenido antes de interactuar con la API. Sanitizar entradas y salidas para asegurar que no contengan informaci√≥n de identificaci√≥n personal o propietaria.\n",
              "  - **Monitorizaci√≥n en Tiempo Real:** Utilizar herramientas de monitorizaci√≥n en tiempo real para revisar y registrar acceso a las API, manteniendo un registro detallado y auditable de todas las transacciones y transferencias de datos, lo cual permite detectar inmediatamente cualquier actividad an√≥mala o no autorizada.\n",
              "\n",
              "### Rama 3: Soluci√≥n Soberana (Modelo Open-Source como Llama 3)\n",
              "\n",
              "- **Riesgo Principal:** Aumento de la carga de responsabilidad en t√©rminos de seguridad debido a la autogesti√≥n completa.\n",
              "\n",
              "- **Medida de Seguridad:**\n",
              "  - **Infraestructura de Servidores Segregada y Fortificada:** Configurar la infraestructura para que el modelo opere dentro de un entorno de servidores dedicados con aislamiento de red y restricciones fuertes en puertos y protocolos permitidos.\n",
              "  - **Implementaci√≥n de Controles Exhaustivos de Acceso:** Desarrollar pol√≠ticas estrictas de control de acceso junto a mecanismos de autenticaci√≥n robusta, como certificados digitales y claves SSH. Auditar el acceso regularmente.\n",
              "  - **Sistema de Parcheo y Actualizaci√≥n R√°pida:** Establecer un sistema automatizado para detectar, testar y aplicar parches de seguridad tan pronto como est√©n disponibles, mitigando vulnerabilidades en el software open-source utilizado.\n",
              "\n",
              "Estas medidas est√°n dise√±adas para abordar las preocupaciones de seguridad en cada eslab√≥n problem√°tico de la cadena de confianza, reduciendo significativamente el riesgo de exposici√≥n de datos o brechas de seguridad. Si tienes m√°s preguntas o necesitas m√°s detalles sobre estas medidas, no dudes en dec√≠rmelo.</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 4924, Respuesta: 747, Total: 5671\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enviar_mensaje(\"Gracias por el apoyo, lo reviso con nuestro jefe y seguimos discutiendo, bonita noche\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "tLxycT5ngjF5",
        "outputId": "c98fb599-c27b-4ed4-9b8c-6f13087e8fac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border: 1px solid #ccc; background-color: #f4faff; color: #000000;\n",
              "                padding: 18px; border-radius: 12px; font-family: sans-serif;\n",
              "                max-width: 800px; line-height: 1.6; font-size: 15px;\n",
              "                max-height: 400px; overflow-y: auto; box-shadow: 0px 4px 10px rgba(0,0,0,0.1);\">\n",
              "        <strong style=\"font-size: 16px;\">gpt-4o responde (Iteraci√≥n #13):</strong><br>\n",
              "        <div style=\"margin-top: 10px; white-space: pre-wrap;\">¬°De nada! Espero que la informaci√≥n proporcionada sea √∫til para tus discusiones. Si necesitas m√°s asistencia o informaci√≥n en el futuro, no dudes en dec√≠rmelo. ¬°Que tengas una buena noche!</div>\n",
              "        <hr style=\"margin-top: 15px; margin-bottom: 5px;\">\n",
              "        <div style=\"font-size: 13px; color: #333;\">\n",
              "            <strong>Tokens usados:</strong>\n",
              "            Prompt: 5698, Respuesta: 42, Total: 5740\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "IU6Io05vsgcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **An√°lisis de T√©cnicas de Prompt Engineering en la Demostraci√≥n**\n",
        "\n",
        "En la libreta se demostr√≥ c√≥mo la calidad y el tipo de prompt influyen directamente en la utilidad y profundidad de la respuesta del LLM. Se utilizaron tres t√©cnicas clave, cada una con un prop√≥sito espec√≠fico y con resultados claramente diferenciados.\n",
        "\n",
        "-----\n",
        "\n",
        "#### **1. Prompting Zero-Shot (Disparo √önico)**\n",
        "\n",
        "Esta es la t√©cnica m√°s directa, donde se le da al modelo una instrucci√≥n simple sin ejemplos previos.\n",
        "\n",
        "  * **Ejemplo del Prompt:**\n",
        "\n",
        "    ```\n",
        "    \"Pres√©ntame la idea inicial del proyecto 'SantanderSQL Shield'.\"\n",
        "    ```\n",
        "\n",
        "  * **Efecto y Prop√≥sito:**\n",
        "    El objetivo era obtener una respuesta r√°pida y una visi√≥n general del concepto del proyecto. Se usa para tareas sencillas donde no se requiere un an√°lisis profundo, sino una descripci√≥n b√°sica.\n",
        "\n",
        "  * **Observaciones de la Respuesta:**\n",
        "\n",
        "      * La respuesta fue coherente y relevante al tema solicitado.\n",
        "      * Sin embargo, fue muy gen√©rica. Describi√≥ los componentes de una soluci√≥n de seguridad de datos (protecci√≥n, detecci√≥n, resiliencia) pero no utiliz√≥ los datos cuantitativos espec√≠ficos del problema (ej. la tasa de error del 18% o el costo de $340,000 USD) que se mencionan en el contexto de la libreta.\n",
        "      * Demostr√≥ que para un caso de negocio que requiere detalle y justificaci√≥n, el enfoque Zero-Shot es insuficiente.\n",
        "\n",
        "-----\n",
        "\n",
        "#### **2. Prompting Chain-of-Thought (CoT) (Cadena de Pensamiento)**\n",
        "\n",
        "Esta t√©cnica gu√≠a al modelo para que descomponga un problema y lo resuelva \"paso a paso\", mejorando la l√≥gica y la estructura de la respuesta.\n",
        "\n",
        "  * **Ejemplo del Prompt:**\n",
        "\n",
        "    ```\n",
        "    \"Elabora una propuesta t√©cnica y de negocio completa para crear el asistente de IA 'SantanderSQL Shield'.\n",
        "\n",
        "    Para asegurar una respuesta bien estructurada, piensa paso a paso:\n",
        "\n",
        "    1.  **Paso 1: Diagn√≥stico del Problema.** Primero, analiza y describe la problem√°tica...\n",
        "    2.  **Paso 2: Definici√≥n de la Soluci√≥n.** A continuaci√≥n, detalla el concepto de 'SantanderSQL Shield'...\n",
        "    3.  **Paso 3: Dise√±o de la Arquitectura.** Despu√©s, define la arquitectura y la pila tecnol√≥gica...\n",
        "    4.  **Paso 4: An√°lisis de Viabilidad.** Finalmente, desarrolla el caso de negocio...\"\n",
        "    ```\n",
        "\n",
        "  * **Efecto y Prop√≥sito:**\n",
        "    El prop√≥sito era forzar al modelo a construir una respuesta mucho m√°s estructurada y detallada. Al darle una secuencia de razonamiento a seguir, se buscaba obtener una propuesta de negocio completa que abordara el problema desde el diagn√≥stico hasta el c√°lculo del ROI.\n",
        "\n",
        "  * **Observaciones de la Respuesta:**\n",
        "\n",
        "      * La calidad de la respuesta mejor√≥ dr√°sticamente. El LLM gener√≥ una propuesta de negocio y t√©cnica completa, organizada exactamente seg√∫n los pasos solicitados.\n",
        "      * A diferencia del Zero-Shot, esta respuesta s√≠ integr√≥ los datos num√©ricos del problema (aunque con algunas alucinaciones en los valores exactos, como un costo anual de $6M en lugar de los $340k del contexto), lo que hizo el caso de negocio mucho m√°s convincente.\n",
        "      * Esta t√©cnica demostr√≥ ser fundamental para pasar de una idea general a un plan de proyecto accionable y bien fundamentado.\n",
        "\n",
        "-----\n",
        "\n",
        "#### **3. Prompting Tree-of-Thoughts (ToT) (√Årbol de Pensamientos)**\n",
        "\n",
        "Es una t√©cnica avanzada donde el modelo debe generar m√∫ltiples l√≠neas de razonamiento (ramas), evaluarlas y luego sintetizar la mejor soluci√≥n.\n",
        "\n",
        "  * **Ejemplo del Prompt:**\n",
        "\n",
        "    ```\n",
        "    \"**Problema Estrat√©gico:** Elabora la mejor propuesta posible... considerando diferentes enfoques.\n",
        "\n",
        "    Para resolver esto, sigue un √°rbol de pensamientos:\n",
        "\n",
        "    **Paso 1: Generaci√≥n de Enfoques (las ramas del √°rbol).**\n",
        "    Primero, genera tres enfoques estrat√©gicos distintos y viables para desarrollar el proyecto:\n",
        "    1.  **Enfoque A (MVP de M√°xima Automatizaci√≥n)...**\n",
        "    2.  **Enfoque B (Asistente Colaborativo 'Human-in-the-Loop')...**\n",
        "    3.  **Enfoque C (Plataforma Empresarial Integral)...**\n",
        "\n",
        "    **Paso 2: Evaluaci√≥n de las Ramas.**\n",
        "    Ahora, eval√∫a de forma cr√≠tica cada uno de los tres enfoques...\n",
        "\n",
        "    **Paso 3: S√≠ntesis y Recomendaci√≥n Final (la mejor ruta).**\n",
        "    Basado en tu evaluaci√≥n comparativa, selecciona el enfoque m√°s adecuado...\"\n",
        "    ```\n",
        "\n",
        "  * **Efecto y Prop√≥sito:**\n",
        "    El objetivo no era solo obtener una soluci√≥n, sino forzar al LLM a realizar un an√°lisis estrat√©gico. Se buscaba que explorara el espacio de posibles soluciones, las comparara de forma cr√≠tica seg√∫n criterios de negocio (seguridad, ROI, escalabilidad) y justificara una decisi√≥n final. Es una t√©cnica para la resoluci√≥n de problemas complejos y la toma de decisiones.\n",
        "\n",
        "  * **Observaciones de la Respuesta:**\n",
        "\n",
        "      * Este m√©todo produjo la respuesta m√°s sofisticada y de mayor valor estrat√©gico.\n",
        "      * El LLM fue capaz de generar y describir claramente tres enfoques distintos, evaluarlos de manera coherente y, lo m√°s importante, recomendar una soluci√≥n h√≠brida que combinaba las mejores caracter√≠sticas de dos de los enfoques, justificando su elecci√≥n.\n",
        "      * El ToT demostr√≥ ser extremadamente poderoso para tareas de consultor√≠a y estrategia, ya que no solo responde a una pregunta, sino que explora, eval√∫a y recomienda el mejor camino a seguir, imitando un proceso de toma de decisiones humano de alto nivel."
      ],
      "metadata": {
        "id": "uL3Xrt4Vsb0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "ivVoho13srzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se presenta un an√°lisis detallado del notebook proporcionado, con las conclusiones finales de la demostraci√≥n, una explicaci√≥n de las t√©cnicas de *Prompt Engineering* utilizadas y las referencias correspondientes.\n",
        "\n",
        "### **Conclusiones Finales de la Demostraci√≥n**\n",
        "\n",
        "El notebook presenta una demostraci√≥n exhaustiva y bien estructurada sobre c√≥mo aplicar un Modelo de Lenguaje Grande (LLM) para resolver un problema de negocio complejo en un entorno corporativo regulado como la banca. El caso de uso, **\"SantanderSQL Shield\"**, es un ejemplo pr√°ctico y de alto impacto sobre c√≥mo la IA generativa puede optimizar procesos cr√≠ticos, reducir costos y mitigar riesgos operativos.\n",
        "\n",
        "Las conclusiones clave de la demostraci√≥n son las siguientes:\n",
        "\n",
        "* **El Prompt es el Pilar del Resultado:** La calidad, profundidad y utilidad de las respuestas del LLM dependieron directamente de la calidad y estructura del prompt. La demostraci√≥n muestra una clara evoluci√≥n desde una idea inicial gen√©rica (con *Zero-Shot*) hasta una propuesta estrat√©gica robusta y evaluada desde m√∫ltiples √°ngulos (con *Tree-of-Thoughts*).\n",
        "* **La Complejidad Requiere T√©cnicas Avanzadas:** Para tareas sencillas, un prompt directo puede ser suficiente. Sin embargo, para desarrollar una propuesta de negocio completa y estrat√©gica, fue necesario guiar el razonamiento del modelo con t√©cnicas como *Chain-of-Thought* (CoT) y *Tree-of-Thoughts* (ToT). Estas metodolog√≠as permitieron descomponer el problema, explorar alternativas y sintetizar soluciones complejas, imitando un proceso de consultor√≠a real.\n",
        "* **La Interacci√≥n Conversacional Refina la Soluci√≥n:** La segunda mitad del notebook demuestra que el uso de LLMs no es un proceso de una sola vez, sino una colaboraci√≥n iterativa. Al adoptar un rol y mantener un historial de conversaci√≥n, fue posible desafiar las respuestas iniciales del modelo, solicitar justificaciones m√°s profundas (como la elecci√≥n de la tecnolog√≠a) y a√±adir capas de an√°lisis cr√≠ticas (como las medidas de seguridad espec√≠ficas), llevando la propuesta de un nivel bueno a uno excelente.\n",
        "* **Capacidad de Adopci√≥n de Personas:** El LLM demostr√≥ ser altamente efectivo en adoptar la persona asignada (\"Asistente Experto en consultor√≠a\") y mantenerla a lo largo de la interacci√≥n. Esto es fundamental para contextualizar las respuestas y asegurar que se alineen con los objetivos, el tono y las restricciones del cliente, en este caso, Santander US Bank.\n",
        "* **Demostraci√≥n de Valor de Negocio:** El proyecto simulado \"SantanderSQL Shield\" presenta un caso de negocio convincente con un Retorno de la Inversi√≥n (ROI) proyectado del 4,267%, lo que subraya el potencial de los LLMs no solo como herramientas tecnol√≥gicas, sino como motores de transformaci√≥n y eficiencia financiera.\n",
        "\n",
        "### **An√°lisis de M√©todos de *Prompt Engineering* Utilizados**\n",
        "\n",
        "El *Prompt Engineering* es el proceso de dise√±ar y refinar las entradas (prompts) para guiar a los LLMs a generar las salidas deseadas de la manera m√°s efectiva posible (Phoenix & Taylor, 2024). El notebook emple√≥ tres t√©cnicas principales:\n",
        "\n",
        "#### 1. **Prompting Zero-Shot (Disparo √önico)**\n",
        "\n",
        "* **¬øPara qu√© sirve?** Es la forma m√°s b√°sica de interactuar con un LLM. Consiste en dar una instrucci√≥n directa y concisa sin proporcionarle ejemplos previos de c√≥mo realizar la tarea (Falc√≥n Morales, 2025). Es √∫til para tareas simples o para obtener una primera idea general sobre un tema.\n",
        "* **Resultados Observados:** En el \"Caso 1: User_Prompt Zero-Shot\", se le pidi√≥ al modelo: *\"Pres√©ntame la idea inicial del proyecto 'SantanderSQL Shield' \"*. La respuesta fue coherente y relevante, pero muy gen√©rica. Describi√≥ los objetivos y componentes de una soluci√≥n de seguridad de bases de datos de manera superficial, sin conectar directamente con los datos espec√≠ficos del problema (costos, tasa de error) ni proponer una arquitectura concreta. Esto demuestra que para un an√°lisis profundo, el Zero-Shot es insuficiente.\n",
        "\n",
        "#### 2. **Prompting Chain-of-Thought (CoT) (Cadena de Pensamiento)**\n",
        "\n",
        "* **¬øPara qu√© sirve?** Esta t√©cnica gu√≠a al modelo para que descomponga un problema complejo en una secuencia de pasos l√≥gicos intermedios antes de llegar a la respuesta final (Falc√≥n Morales, 2025). Al instruir al modelo a \"pensar paso a paso\", se mejora significativamente la calidad y la estructura del razonamiento, especialmente en tareas que requieren an√°lisis detallado.\n",
        "* **Resultados Observados:** En el \"Caso 2: User_Prompt Chain-of-Thought (CoT)\", el prompt se estructur√≥ en cuatro pasos claros: Diagn√≥stico, Soluci√≥n, Arquitectura y Viabilidad. Como resultado, la respuesta del LLM fue una propuesta de negocio completa y bien organizada. A diferencia del Zero-Shot, esta respuesta utiliz√≥ datos cuantitativos del problema para justificar la soluci√≥n y detall√≥ la pila tecnol√≥gica y el an√°lisis de ROI. La metodolog√≠a CoT transform√≥ una idea vaga en un plan de proyecto accionable.\n",
        "\n",
        "#### 3. **Prompting Tree-of-Thoughts (ToT) (√Årbol de Pensamientos)**\n",
        "\n",
        "* **¬øPara qu√© sirve?** Es una t√©cnica m√°s avanzada que la CoT. En lugar de seguir una √∫nica cadena de pensamiento, el ToT instruye al modelo a generar y explorar m√∫ltiples l√≠neas de razonamiento (ramas), evaluarlas de forma cr√≠tica seg√∫n ciertos criterios y luego sintetizar la mejor soluci√≥n posible, a menudo combinando las fortalezas de las diferentes ramas (Falc√≥n Morales, 2025). Es ideal para la toma de decisiones estrat√©gicas y la resoluci√≥n de problemas complejos sin una √∫nica respuesta correcta.\n",
        "* **Resultados Observados:** El \"Caso 3: User_Prompt Tree-of-Thoughts (ToT)\" es el ejemplo m√°s sofisticado del notebook. El prompt oblig√≥ al modelo a generar tres enfoques estrat√©gicos distintos (MVP, Asistente Colaborativo y Plataforma Integral), evaluarlos seg√∫n criterios clave (seguridad, ROI, escalabilidad) y, finalmente, recomendar una soluci√≥n h√≠brida que combinaba lo mejor de dos enfoques. Este resultado demuestra un nivel de razonamiento estrat√©gico muy superior. La conversaci√≥n posterior, donde se usa este mismo enfoque para comparar proveedores de LLM y luego proponer medidas de seguridad espec√≠ficas para cada uno, refuerza la potencia del ToT para an√°lisis comparativos y mitigaci√≥n de riesgos.\n",
        "\n",
        "### **Referencias**\n",
        "\n",
        "Falc√≥n Morales, L. E. (2025). *MNA_NLP_LLM_prompts.pdf* [Materia de NLP, Tec de Monterrey]. Junio 2025.\n",
        "\n",
        "Falc√≥n Morales, L. E. (2025). *MNA_NLP_prompts_OpenAI_clase-1.ipynb* [Materia de NLP, Tec de Monterrey]. Junio 2025.\n",
        "\n",
        "OpenAI. (2024). *GPT-4o*. [https://platform.openai.com/docs/guides/gpt](https://platform.openai.com/docs/guides/gpt)\n",
        "\n",
        "Phoenix, J., & Taylor, M. (2024). *Prompt Engineering for Generative AI*. O'Reilly. [https://learning.oreilly.com/library/view/prompt-engineering-for/9781098153427/](https://learning.oreilly.com/library/view/prompt-engineering-for/9781098153427/)"
      ],
      "metadata": {
        "id": "qPNvSbohstNx"
      }
    }
  ]
}